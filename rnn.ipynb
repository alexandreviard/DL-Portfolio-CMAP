{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tahah\\anaconda3\\envs\\riemann\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] La procédure spécifiée est introuvable'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision #for dataset \n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PortfolioRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        # x -> (batch_size, timesteps/seq, input_size/feature_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, r):\n",
    "        h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.rnn(X,h0)\n",
    "        # out -> (batch_size, seq_length, hidden_size)\n",
    "        #out = out[:,-1,:] only take the last time step NO WE NEED ALL TIME STEPS\n",
    "        out = self.linear(out)\n",
    "        out = torch.softmax(out, dim=-1)\n",
    "        portfolio_returns = torch.sum(out[:, :, :] * r[:, :, :], dim=-1)\n",
    "        # portfolio_returns -> (batch_size)\n",
    "        sharpe = torch.mean(portfolio_returns, dim = -1) / torch.std(portfolio_returns, dim = -1)\n",
    "        return -sharpe.mean()\n",
    "    \n",
    "    def get_allocations(self, X):\n",
    "        with torch.no_grad():\n",
    "            h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_size).to(device)\n",
    "            out, _ = self.rnn(X,h0)\n",
    "            out = self.linear(out)\n",
    "            out = torch.softmax(out, dim=-1)\n",
    "        return out[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_R'] = data_na[f'{column}'].pct_change()\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_y'] = data_na[f'{column}_R'].shift(-1)\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_R'] = data_na[f'{column}'].pct_change()\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_y'] = data_na[f'{column}_R'].shift(-1)\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_R'] = data_na[f'{column}'].pct_change()\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_y'] = data_na[f'{column}_R'].shift(-1)\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_R'] = data_na[f'{column}'].pct_change()\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na[f'{column}_y'] = data_na[f'{column}_R'].shift(-1)\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na.dropna(axis=0, inplace=True)\n",
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\376173755.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na['Date'] = data_na['Date'].dt.date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>AGG</th>\n",
       "      <th>DBC</th>\n",
       "      <th>VTI</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>AGG_R</th>\n",
       "      <th>AGG_y</th>\n",
       "      <th>DBC_R</th>\n",
       "      <th>DBC_y</th>\n",
       "      <th>VTI_R</th>\n",
       "      <th>VTI_y</th>\n",
       "      <th>^VIX_R</th>\n",
       "      <th>^VIX_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-02-07</td>\n",
       "      <td>56.438538</td>\n",
       "      <td>20.285255</td>\n",
       "      <td>44.219498</td>\n",
       "      <td>13.590000</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.028926</td>\n",
       "      <td>-0.004255</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>-0.055923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-02-08</td>\n",
       "      <td>56.410393</td>\n",
       "      <td>20.198933</td>\n",
       "      <td>44.537632</td>\n",
       "      <td>12.830000</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>-0.004255</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.055923</td>\n",
       "      <td>0.022603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-02-09</td>\n",
       "      <td>56.444248</td>\n",
       "      <td>20.388842</td>\n",
       "      <td>44.452785</td>\n",
       "      <td>13.120000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>-0.018205</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.022603</td>\n",
       "      <td>-0.019055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-02-10</td>\n",
       "      <td>56.325848</td>\n",
       "      <td>20.017662</td>\n",
       "      <td>44.544689</td>\n",
       "      <td>12.870000</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.018205</td>\n",
       "      <td>-0.015524</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.004523</td>\n",
       "      <td>-0.019055</td>\n",
       "      <td>0.037296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-02-13</td>\n",
       "      <td>56.365253</td>\n",
       "      <td>19.706907</td>\n",
       "      <td>44.343197</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>-0.015524</td>\n",
       "      <td>-0.008322</td>\n",
       "      <td>-0.004523</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>-0.082397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>106.759193</td>\n",
       "      <td>13.624199</td>\n",
       "      <td>181.857010</td>\n",
       "      <td>24.230000</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.011004</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>-0.036963</td>\n",
       "      <td>-0.037969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>106.686768</td>\n",
       "      <td>13.794738</td>\n",
       "      <td>182.168076</td>\n",
       "      <td>23.309999</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.037969</td>\n",
       "      <td>-0.076362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>106.786339</td>\n",
       "      <td>13.832635</td>\n",
       "      <td>182.472778</td>\n",
       "      <td>21.530001</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>-0.076362</td>\n",
       "      <td>0.007896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>106.804451</td>\n",
       "      <td>13.747366</td>\n",
       "      <td>183.627274</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.063594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>106.822548</td>\n",
       "      <td>13.785263</td>\n",
       "      <td>182.860764</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.063594</td>\n",
       "      <td>-0.013432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3750 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker        Date         AGG        DBC         VTI       ^VIX     AGG_R  \\\n",
       "0       2006-02-07   56.438538  20.285255   44.219498  13.590000 -0.000699   \n",
       "1       2006-02-08   56.410393  20.198933   44.537632  12.830000 -0.000499   \n",
       "2       2006-02-09   56.444248  20.388842   44.452785  13.120000  0.000600   \n",
       "3       2006-02-10   56.325848  20.017662   44.544689  12.870000 -0.002098   \n",
       "4       2006-02-13   56.365253  19.706907   44.343197  13.350000  0.000700   \n",
       "...            ...         ...        ...         ...        ...       ...   \n",
       "3745    2020-12-22  106.759193  13.624199  181.857010  24.230000  0.001443   \n",
       "3746    2020-12-23  106.686768  13.794738  182.168076  23.309999 -0.000678   \n",
       "3747    2020-12-24  106.786339  13.832635  182.472778  21.530001  0.000933   \n",
       "3748    2020-12-28  106.804451  13.747366  183.627274  21.700001  0.000170   \n",
       "3749    2020-12-29  106.822548  13.785263  182.860764  23.080000  0.000169   \n",
       "\n",
       "Ticker     AGG_y     DBC_R     DBC_y     VTI_R     VTI_y    ^VIX_R    ^VIX_y  \n",
       "0      -0.000499 -0.028926 -0.004255 -0.009736  0.007194  0.042178 -0.055923  \n",
       "1       0.000600 -0.004255  0.009402  0.007194 -0.001905 -0.055923  0.022603  \n",
       "2      -0.002098  0.009402 -0.018205 -0.001905  0.002067  0.022603 -0.019055  \n",
       "3       0.000700 -0.018205 -0.015524  0.002067 -0.004523 -0.019055  0.037296  \n",
       "4      -0.001599 -0.015524 -0.008322 -0.004523  0.009486  0.037296 -0.082397  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "3745   -0.000678 -0.011004  0.012517  0.000207  0.001710 -0.036963 -0.037969  \n",
       "3746    0.000933  0.012517  0.002747  0.001710  0.001673 -0.037969 -0.076362  \n",
       "3747    0.000170  0.002747 -0.006164  0.001673  0.006327 -0.076362  0.007896  \n",
       "3748    0.000169 -0.006164  0.002757  0.006327 -0.004174  0.007896  0.063594  \n",
       "3749    0.000593  0.002757  0.006186 -0.004174  0.002691  0.063594 -0.013432  \n",
       "\n",
       "[3750 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "tickers = ['VTI', 'AGG', 'DBC', '^VIX']\n",
    "data = yf.download(tickers, start=\"2006-01-01\", end=\"2020-12-31\", interval=\"1d\")['Adj Close']\n",
    "data_na = data.dropna(axis = 0)\n",
    "for column in data_na.columns:\n",
    "    data_na[f'{column}_R'] = data_na[f'{column}'].pct_change()\n",
    "    #le rendement du jour suivant\n",
    "    data_na[f'{column}_y'] = data_na[f'{column}_R'].shift(-1)\n",
    "data_na.dropna(axis=0, inplace=True)\n",
    "data_na.reset_index(inplace=True)\n",
    "data_na['Date'] = data_na['Date'].dt.date\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\2991668214.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['Date'] = pd.to_datetime(dataframe['Date'])\n"
     ]
    }
   ],
   "source": [
    "def create_batches(dataframe, start_date, end_date, window_size=50):\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'])\n",
    "    \n",
    "    filtered_data = dataframe[(dataframe['Date'] >= start_date) & (dataframe['Date'] <= end_date)]\n",
    "    \n",
    "    x_batches = []\n",
    "    y_batches = []\n",
    "    dates_batches = []\n",
    "    dates_per_feature = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(filtered_data) - window_size):\n",
    "        window_returns = filtered_data.iloc[i:i+window_size][[col for col in dataframe.columns if col.endswith('_R')]].values\n",
    "        window_prices = filtered_data.iloc[i:i+window_size][[col for col in dataframe.columns if col in ['AGG', 'DBC', 'VTI', '^VIX']]].values\n",
    "        window_x = np.concatenate([window_returns, window_prices], axis=1)\n",
    "        window_y = filtered_data.iloc[i:i+window_size][[col for col in dataframe.columns if col.endswith('_y')]].values\n",
    "        \n",
    "        window_dates_batches = filtered_data.iloc[i:i+window_size]['Date'].values\n",
    "        dates_per_feature.append(filtered_data.iloc[i+window_size]['Date'].date()) \n",
    "\n",
    "        y.append(filtered_data.iloc[i+window_size][[col for col in dataframe.columns if col.endswith('_y')]].values)\n",
    "\n",
    "        x_batches.append(window_x)\n",
    "        y_batches.append(window_y)\n",
    "        dates_batches.append(window_dates_batches)\n",
    "\n",
    "    return np.array(x_batches), np.array(y_batches), np.array(y, dtype=np.float32), np.array(dates_batches), dates_per_feature\n",
    "\n",
    "x_batches, y_batches, y, dates_batches, dates_per_feature = create_batches(data_na, start_date=\"2006-01-01\", end_date=\"2020-12-29\")\n",
    "y = y.reshape(y.shape[0], 1, y.shape[1])\n",
    "\n",
    "#dates_per_feature représente la date à laquelle la valeur de la cible (dans y) est observée: c les 51èmes valeurs donc la valeur qui suit chaque window de 50 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dates_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na.iloc[10]['Date'].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na.iloc[:10]['Date'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_returns = data_na.iloc[:10][['AGG_R', 'DBC_R']].values\n",
    "window_prices = data_na.iloc[:10][[col for col in data_na.columns if col in ['AGG', 'DBC']]].values\n",
    "\n",
    "window_returns.shape, window_prices.shape\n",
    "\n",
    "concatenaed = np.concatenate([window_returns, window_prices], axis=1)\n",
    "concatenaed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def get_idx_dates(start_date, end_date):\n",
    "    if start_date in dates_per_feature and end_date in dates_per_feature:\n",
    "        k_start = dates_per_feature.index(start_date)\n",
    "        k_end = dates_per_feature.index(end_date)\n",
    "        return k_start, k_end\n",
    "    \n",
    "    if start_date not in dates_per_feature: \n",
    "        if any(dates >= start_date for dates in dates_per_feature):    \n",
    "            k_start = min(j for j in range(len(dates_per_feature)) if dates_per_feature[j] >= start_date)\n",
    "        else:\n",
    "            k_start = 0\n",
    "    else:\n",
    "        k_start = dates_per_feature.index(start_date)\n",
    "\n",
    "    if end_date not in dates_per_feature:\n",
    "        if any(dates <= end_date for dates in dates_per_feature):\n",
    "            k_end = max(j for j in range(len(dates_per_feature)) if dates_per_feature[j] <= end_date) + 1\n",
    "        else:\n",
    "            k_end = len(dates_per_feature) -1\n",
    "    else: \n",
    "        k_end = dates_per_feature.index(end_date)\n",
    "\n",
    "    return k_start, k_end\n",
    "\n",
    "\n",
    "def training(x_batches, y_batches, model, batch_size):\n",
    "\n",
    "    x_batches_tensor = torch.tensor(x_batches, dtype=torch.float32)\n",
    "    y_batches_tensor = torch.tensor(y_batches, dtype=torch.float32)\n",
    "    num_batches = x_batches.shape[0]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 100\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        \n",
    "        for i in range(0, num_batches, batch_size):\n",
    "            x_mini_batch = x_batches_tensor[i:i+batch_size]\n",
    "            y_mini_batch = y_batches_tensor[i:i+batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = model(x_mini_batch, y_mini_batch)\n",
    "            loss_epoch += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"epoch [{epoch+1}/{num_epochs}], loss: {(loss_epoch/batch_size)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def investing(x_batches, y, model):\n",
    "\n",
    "    x_tensor = torch.tensor(x_batches, dtype=torch.float32)\n",
    "    allocations = model.get_allocations(x_tensor)\n",
    "    # pourquoi ce shape ?\n",
    "    allocations = allocations.view(allocations.shape[0], 1, allocations.shape[1])\n",
    "    rdt = torch.sum(allocations*y, dim=2)\n",
    "\n",
    "    # return du portfeuille à t final du rnn, les allocations\n",
    "    return rdt, allocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: -0.029385375937636127\n",
      "epoch [2/100], loss: -0.03307000907079782\n",
      "epoch [3/100], loss: -0.04018617179826833\n",
      "epoch [4/100], loss: -0.03156034466519486\n",
      "epoch [5/100], loss: -0.040701317571802065\n",
      "epoch [6/100], loss: -0.03472963490639813\n",
      "epoch [7/100], loss: -0.043660113915393595\n",
      "epoch [8/100], loss: -0.038916635798159405\n",
      "epoch [9/100], loss: -0.04196471803879831\n",
      "epoch [10/100], loss: -0.044280828136834316\n",
      "epoch [11/100], loss: -0.04768573050387204\n",
      "epoch [12/100], loss: -0.041050448548048735\n",
      "epoch [13/100], loss: -0.03955679957289249\n",
      "epoch [14/100], loss: -0.032119931229317444\n",
      "epoch [15/100], loss: -0.04176261443353724\n",
      "epoch [16/100], loss: -0.04353887538309209\n",
      "epoch [17/100], loss: -0.05077271064510569\n",
      "epoch [18/100], loss: -0.048479116576345405\n",
      "epoch [19/100], loss: -0.05474630840035388\n",
      "epoch [20/100], loss: -0.05331587987893727\n",
      "epoch [21/100], loss: -0.056429067939461675\n",
      "epoch [22/100], loss: -0.05400195966285537\n",
      "epoch [23/100], loss: -0.054336018365575\n",
      "epoch [24/100], loss: -0.054390615769079886\n",
      "epoch [25/100], loss: -0.052423966146307066\n",
      "epoch [26/100], loss: -0.052585400408133864\n",
      "epoch [27/100], loss: -0.046225925456383266\n",
      "epoch [28/100], loss: -0.06013356600305997\n",
      "epoch [29/100], loss: -0.05940205246952246\n",
      "epoch [30/100], loss: -0.05968269138247706\n",
      "epoch [31/100], loss: -0.05879116052528843\n",
      "epoch [32/100], loss: -0.05331933923298493\n",
      "epoch [33/100], loss: -0.0547330898407381\n",
      "epoch [34/100], loss: -0.0582826288882643\n",
      "epoch [35/100], loss: -0.06334041399531998\n",
      "epoch [36/100], loss: -0.061258921632543206\n",
      "epoch [37/100], loss: -0.06413302995497361\n",
      "epoch [38/100], loss: -0.06624547770479694\n",
      "epoch [39/100], loss: -0.06448117771651596\n",
      "epoch [40/100], loss: -0.059351517556933686\n",
      "epoch [41/100], loss: -0.06360497311106883\n",
      "epoch [42/100], loss: -0.05197657202370465\n",
      "epoch [43/100], loss: -0.06504517048597336\n",
      "epoch [44/100], loss: -0.0643507856875658\n",
      "epoch [45/100], loss: -0.06229373789392412\n",
      "epoch [46/100], loss: -0.06009265915781725\n",
      "epoch [47/100], loss: -0.06593629630515352\n",
      "epoch [48/100], loss: -0.06048666423885152\n",
      "epoch [49/100], loss: -0.06603330705547705\n",
      "epoch [50/100], loss: -0.0665890175732784\n",
      "epoch [51/100], loss: -0.06942019163398072\n",
      "epoch [52/100], loss: -0.0715963042457588\n",
      "epoch [53/100], loss: -0.07119562034495175\n",
      "epoch [54/100], loss: -0.06207425065804273\n",
      "epoch [55/100], loss: -0.06874555750982836\n",
      "epoch [56/100], loss: -0.07160665583796799\n",
      "epoch [57/100], loss: -0.07674102357123047\n",
      "epoch [58/100], loss: -0.07553434034343809\n",
      "epoch [59/100], loss: -0.07521943107713014\n",
      "epoch [60/100], loss: -0.07109911902807653\n",
      "epoch [61/100], loss: -0.07074658013880253\n",
      "epoch [62/100], loss: -0.07291346142301336\n",
      "epoch [63/100], loss: -0.07590332010295242\n",
      "epoch [64/100], loss: -0.07702760223764926\n",
      "epoch [65/100], loss: -0.06709097838029265\n",
      "epoch [66/100], loss: -0.06789522268809378\n",
      "epoch [67/100], loss: -0.0724053934100084\n",
      "epoch [68/100], loss: -0.07370379869826138\n",
      "epoch [69/100], loss: -0.08067977882456034\n",
      "epoch [70/100], loss: -0.07973230048082769\n",
      "epoch [71/100], loss: -0.07664223574101925\n",
      "epoch [72/100], loss: -0.07301959069445729\n",
      "epoch [73/100], loss: -0.07498082128586248\n",
      "epoch [74/100], loss: -0.07794927293434739\n",
      "epoch [75/100], loss: -0.08576269482728094\n",
      "epoch [76/100], loss: -0.08220083999913186\n",
      "epoch [77/100], loss: -0.08217865508049726\n",
      "epoch [78/100], loss: -0.08186512580141425\n",
      "epoch [79/100], loss: -0.0888861664570868\n",
      "epoch [80/100], loss: -0.0889773549279198\n",
      "epoch [81/100], loss: -0.07807029248215258\n",
      "epoch [82/100], loss: -0.07796022691763937\n",
      "epoch [83/100], loss: -0.07970704394392669\n",
      "epoch [84/100], loss: -0.08409214718267322\n",
      "epoch [85/100], loss: -0.08893835463095456\n",
      "epoch [86/100], loss: -0.09158347547054291\n",
      "epoch [87/100], loss: -0.0911203061696142\n",
      "epoch [88/100], loss: -0.0856689135544002\n",
      "epoch [89/100], loss: -0.08613457425963134\n",
      "epoch [90/100], loss: -0.08980146795511246\n",
      "epoch [91/100], loss: -0.08336111553944647\n",
      "epoch [92/100], loss: -0.08459057414438576\n",
      "epoch [93/100], loss: -0.09355857945047319\n",
      "epoch [94/100], loss: -0.092190086026676\n",
      "epoch [95/100], loss: -0.09360349294729531\n",
      "epoch [96/100], loss: -0.09618175984360278\n",
      "epoch [97/100], loss: -0.08991694427095354\n",
      "epoch [98/100], loss: -0.09056978789158165\n",
      "epoch [99/100], loss: -0.0940114117693156\n",
      "epoch [100/100], loss: -0.0882411184720695\n",
      "Idx start: 1005, Idx end: 1510\n",
      "2010-04-19 2012-04-18\n",
      "torch.Size([505, 1]) 505\n",
      "first_rdt shape: torch.Size([505, 1]), rdt_all shape before concat: torch.Size([0, 0])\n"
     ]
    }
   ],
   "source": [
    "input_size = 8\n",
    "hidden_size = 64\n",
    "output_size = 4\n",
    "batch_size = 64\n",
    "\n",
    "rdt_all = torch.empty(0,0)\n",
    "alloc_all = []\n",
    "idx_invest = []\n",
    "dates_invest = []\n",
    "\n",
    "# first training goes from 2006 to 2010\n",
    "first_date = dates_per_feature[0]\n",
    "end_date_1st_training = first_date + datetime.timedelta(days=365*4)\n",
    "\n",
    "# trouve le premier batch et le dernier batch correspondant\n",
    "idx_start, idx_end = get_idx_dates(first_date, end_date_1st_training)\n",
    "\n",
    "model = PortfolioRNN(input_size=input_size, hidden_size=hidden_size, num_layers = 2,output_size=output_size)\n",
    "\n",
    "\n",
    "model = training(x_batches = x_batches[idx_start:idx_end, :, :],\n",
    "                      y_batches= y_batches[idx_start:idx_end, :, :],\n",
    "                      model=model,\n",
    "                      batch_size=64)\n",
    "\n",
    "# un an c pas 365 jours mais 252 jours de trading\n",
    "date_end_invest = end_date_1st_training + datetime.timedelta(days=365*2)\n",
    "idx_start_invest, idx_end_invest = get_idx_dates(end_date_1st_training, date_end_invest)\n",
    "\n",
    "print(f\"Idx start: {idx_start_invest}, Idx end: {idx_end_invest}\")\n",
    "print(dates_per_feature[idx_start_invest], dates_per_feature[idx_end_invest])\n",
    "\n",
    "idx_invest.append((idx_start_invest, idx_end_invest))\n",
    "dates_invest.append((end_date_1st_training, date_end_invest))\n",
    "\n",
    "x_investing = x_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "y_investing = y_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "y_real = y[idx_start_invest:idx_end_invest, :, :]\n",
    "\n",
    "first_rdt, first_alloc = investing(x_batches= x_investing, y=y_real, model=model)\n",
    "\n",
    "print(first_rdt.shape, len(dates_per_feature[idx_start_invest:idx_end_invest]))\n",
    "\n",
    "print(f\"first_rdt shape: {first_rdt.shape}, rdt_all shape before concat: {rdt_all.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_alloc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: -0.024832538794726133\n",
      "epoch [2/100], loss: -0.034344499465078115\n",
      "epoch [3/100], loss: -0.038555337116122246\n",
      "epoch [4/100], loss: -0.04193546692840755\n",
      "epoch [5/100], loss: -0.043892650632187724\n",
      "epoch [6/100], loss: -0.04602160467766225\n",
      "epoch [7/100], loss: -0.04618793702684343\n",
      "epoch [8/100], loss: -0.047210816061124206\n",
      "epoch [9/100], loss: -0.04887378145940602\n",
      "epoch [10/100], loss: -0.048813041765242815\n",
      "epoch [11/100], loss: -0.0489580393768847\n",
      "epoch [12/100], loss: -0.04846715950407088\n",
      "epoch [13/100], loss: -0.05027770507149398\n",
      "epoch [14/100], loss: -0.050180085469037294\n",
      "epoch [15/100], loss: -0.052126366179436445\n",
      "epoch [16/100], loss: -0.052794078597798944\n",
      "epoch [17/100], loss: -0.055410209111869335\n",
      "epoch [18/100], loss: -0.05309193045832217\n",
      "epoch [19/100], loss: -0.054598760325461626\n",
      "epoch [20/100], loss: -0.054940992500633\n",
      "epoch [21/100], loss: -0.05780458124354482\n",
      "epoch [22/100], loss: -0.05372153199277818\n",
      "epoch [23/100], loss: -0.05369267472997308\n",
      "epoch [24/100], loss: -0.051303347107023\n",
      "epoch [25/100], loss: -0.05098532838746905\n",
      "epoch [26/100], loss: -0.053594854194670916\n",
      "epoch [27/100], loss: -0.054238686338067055\n",
      "epoch [28/100], loss: -0.056081704795360565\n",
      "epoch [29/100], loss: -0.05886533809825778\n",
      "epoch [30/100], loss: -0.06114981044083834\n",
      "epoch [31/100], loss: -0.05647024745121598\n",
      "epoch [32/100], loss: -0.05939145106822252\n",
      "epoch [33/100], loss: -0.05859125382266939\n",
      "epoch [34/100], loss: -0.059372855350375175\n",
      "epoch [35/100], loss: -0.06169331423006952\n",
      "epoch [36/100], loss: -0.061104235239326954\n",
      "epoch [37/100], loss: -0.06557429302483797\n",
      "epoch [38/100], loss: -0.06566935637965798\n",
      "epoch [39/100], loss: -0.06741806259378791\n",
      "epoch [40/100], loss: -0.06822462799027562\n",
      "epoch [41/100], loss: -0.07132908003404737\n",
      "epoch [42/100], loss: -0.06959916604682803\n",
      "epoch [43/100], loss: -0.06334789237007499\n",
      "epoch [44/100], loss: -0.06514201126992702\n",
      "epoch [45/100], loss: -0.06667381711304188\n",
      "epoch [46/100], loss: -0.06915652984753251\n",
      "epoch [47/100], loss: -0.06674705259501934\n",
      "epoch [48/100], loss: -0.06873252475634217\n",
      "epoch [49/100], loss: -0.06738143414258957\n",
      "epoch [50/100], loss: -0.07206949777901173\n",
      "epoch [51/100], loss: -0.07484647212550044\n",
      "epoch [52/100], loss: -0.07568033179268241\n",
      "epoch [53/100], loss: -0.07079737354069948\n",
      "epoch [54/100], loss: -0.06906413100659847\n",
      "epoch [55/100], loss: -0.06656497903168201\n",
      "epoch [56/100], loss: -0.06894758017733693\n",
      "epoch [57/100], loss: -0.07112417835742235\n",
      "epoch [58/100], loss: -0.07531313132494688\n",
      "epoch [59/100], loss: -0.0772792580537498\n",
      "epoch [60/100], loss: -0.07253329968079925\n",
      "epoch [61/100], loss: -0.07201368687674403\n",
      "epoch [62/100], loss: -0.07006078772246838\n",
      "epoch [63/100], loss: -0.07040022173896432\n",
      "epoch [64/100], loss: -0.07404921343550086\n",
      "epoch [65/100], loss: -0.07554470049217343\n",
      "epoch [66/100], loss: -0.07553850533440709\n",
      "epoch [67/100], loss: -0.07484919391572475\n",
      "epoch [68/100], loss: -0.07358716754242778\n",
      "epoch [69/100], loss: -0.07864378159865737\n",
      "epoch [70/100], loss: -0.08302372135221958\n",
      "epoch [71/100], loss: -0.08538192883133888\n",
      "epoch [72/100], loss: -0.08453383948653936\n",
      "epoch [73/100], loss: -0.08315265085548162\n",
      "epoch [74/100], loss: -0.07600505091249943\n",
      "epoch [75/100], loss: -0.06872358499094844\n",
      "epoch [76/100], loss: -0.06735945213586092\n",
      "epoch [77/100], loss: -0.07544268714264035\n",
      "epoch [78/100], loss: -0.0823099403642118\n",
      "epoch [79/100], loss: -0.08430254412814975\n",
      "epoch [80/100], loss: -0.08640502067282796\n",
      "epoch [81/100], loss: -0.08706083288416266\n",
      "epoch [82/100], loss: -0.08777506556361914\n",
      "epoch [83/100], loss: -0.08791521098464727\n",
      "epoch [84/100], loss: -0.08597526606172323\n",
      "epoch [85/100], loss: -0.08464996237307787\n",
      "epoch [86/100], loss: -0.0823124349117279\n",
      "epoch [87/100], loss: -0.0860286089591682\n",
      "epoch [88/100], loss: -0.0884674396365881\n",
      "epoch [89/100], loss: -0.09242333006113768\n",
      "epoch [90/100], loss: -0.09205662459135056\n",
      "epoch [91/100], loss: -0.09189401287585497\n",
      "epoch [92/100], loss: -0.08782264962792397\n",
      "epoch [93/100], loss: -0.09334234427660704\n",
      "epoch [94/100], loss: -0.0877749570645392\n",
      "epoch [95/100], loss: -0.09167760005220771\n",
      "epoch [96/100], loss: -0.09216560516506433\n",
      "epoch [97/100], loss: -0.09306466020643711\n",
      "epoch [98/100], loss: -0.08693950017914176\n",
      "epoch [99/100], loss: -0.09205794893205166\n",
      "epoch [100/100], loss: -0.09041814599186182\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 1008\n",
      "len des dates 1008\n",
      "epoch [1/100], loss: -0.010068496834719554\n",
      "epoch [2/100], loss: -0.01595115987583995\n",
      "epoch [3/100], loss: -0.02315711951814592\n",
      "epoch [4/100], loss: -0.028292259899899364\n",
      "epoch [5/100], loss: -0.03246376267634332\n",
      "epoch [6/100], loss: -0.03443462331779301\n",
      "epoch [7/100], loss: -0.037011843640357256\n",
      "epoch [8/100], loss: -0.03797301184386015\n",
      "epoch [9/100], loss: -0.04034850443713367\n",
      "epoch [10/100], loss: -0.041642029071226716\n",
      "epoch [11/100], loss: -0.04245141986757517\n",
      "epoch [12/100], loss: -0.043433146784082055\n",
      "epoch [13/100], loss: -0.04413404501974583\n",
      "epoch [14/100], loss: -0.04449892439879477\n",
      "epoch [15/100], loss: -0.044075570069253445\n",
      "epoch [16/100], loss: -0.04445314290933311\n",
      "epoch [17/100], loss: -0.04322325484827161\n",
      "epoch [18/100], loss: -0.04381926148198545\n",
      "epoch [19/100], loss: -0.04335431009531021\n",
      "epoch [20/100], loss: -0.044735993491485715\n",
      "epoch [21/100], loss: -0.04543440416455269\n",
      "epoch [22/100], loss: -0.04749190481379628\n",
      "epoch [23/100], loss: -0.04604495060630143\n",
      "epoch [24/100], loss: -0.04622749122790992\n",
      "epoch [25/100], loss: -0.0456040776334703\n",
      "epoch [26/100], loss: -0.04364322591573\n",
      "epoch [27/100], loss: -0.046742874663323164\n",
      "epoch [28/100], loss: -0.04901091195642948\n",
      "epoch [29/100], loss: -0.0492863398976624\n",
      "epoch [30/100], loss: -0.048661136301234365\n",
      "epoch [31/100], loss: -0.048100282438099384\n",
      "epoch [32/100], loss: -0.04858664842322469\n",
      "epoch [33/100], loss: -0.05067410133779049\n",
      "epoch [34/100], loss: -0.052466136403381824\n",
      "epoch [35/100], loss: -0.05297128017991781\n",
      "epoch [36/100], loss: -0.05337433726526797\n",
      "epoch [37/100], loss: -0.05379978567361832\n",
      "epoch [38/100], loss: -0.054419533582404256\n",
      "epoch [39/100], loss: -0.054331447929143906\n",
      "epoch [40/100], loss: -0.0536186620593071\n",
      "epoch [41/100], loss: -0.04700554208829999\n",
      "epoch [42/100], loss: -0.05114530911669135\n",
      "epoch [43/100], loss: -0.052713166922330856\n",
      "epoch [44/100], loss: -0.048901904840022326\n",
      "epoch [45/100], loss: -0.05396189633756876\n",
      "epoch [46/100], loss: -0.055949848145246506\n",
      "epoch [47/100], loss: -0.05648526782169938\n",
      "epoch [48/100], loss: -0.05663863569498062\n",
      "epoch [49/100], loss: -0.058255710639059544\n",
      "epoch [50/100], loss: -0.05749215558171272\n",
      "epoch [51/100], loss: -0.05850666342303157\n",
      "epoch [52/100], loss: -0.05838216422125697\n",
      "epoch [53/100], loss: -0.06003639055415988\n",
      "epoch [54/100], loss: -0.05846413969993591\n",
      "epoch [55/100], loss: -0.05884863017126918\n",
      "epoch [56/100], loss: -0.05615856032818556\n",
      "epoch [57/100], loss: -0.05480146314948797\n",
      "epoch [58/100], loss: -0.05594112304970622\n",
      "epoch [59/100], loss: -0.05667795520275831\n",
      "epoch [60/100], loss: -0.05520753934979439\n",
      "epoch [61/100], loss: -0.052890406223014\n",
      "epoch [62/100], loss: -0.0549027503002435\n",
      "epoch [63/100], loss: -0.05666401423513889\n",
      "epoch [64/100], loss: -0.056567493826150894\n",
      "epoch [65/100], loss: -0.0568300923332572\n",
      "epoch [66/100], loss: -0.05718661332502961\n",
      "epoch [67/100], loss: -0.057793512009084225\n",
      "epoch [68/100], loss: -0.06103899981826544\n",
      "epoch [69/100], loss: -0.06231142254546285\n",
      "epoch [70/100], loss: -0.06295564770698547\n",
      "epoch [71/100], loss: -0.06317759398370981\n",
      "epoch [72/100], loss: -0.06460901629179716\n",
      "epoch [73/100], loss: -0.0627715396694839\n",
      "epoch [74/100], loss: -0.06377938715741038\n",
      "epoch [75/100], loss: -0.0644736671820283\n",
      "epoch [76/100], loss: -0.06346810609102249\n",
      "epoch [77/100], loss: -0.06425936566665769\n",
      "epoch [78/100], loss: -0.06250267988070846\n",
      "epoch [79/100], loss: -0.06285707466304302\n",
      "epoch [80/100], loss: -0.06459795637056231\n",
      "epoch [81/100], loss: -0.0632405485957861\n",
      "epoch [82/100], loss: -0.06180826714262366\n",
      "epoch [83/100], loss: -0.06548170000314713\n",
      "epoch [84/100], loss: -0.06399743258953094\n",
      "epoch [85/100], loss: -0.06568642798811197\n",
      "epoch [86/100], loss: -0.06671393802389503\n",
      "epoch [87/100], loss: -0.06560741737484932\n",
      "epoch [88/100], loss: -0.06592683121562004\n",
      "epoch [89/100], loss: -0.06742371106520295\n",
      "epoch [90/100], loss: -0.06862818030640483\n",
      "epoch [91/100], loss: -0.06862760847434402\n",
      "epoch [92/100], loss: -0.06719107879325747\n",
      "epoch [93/100], loss: -0.06912701576948166\n",
      "epoch [94/100], loss: -0.06920137675479054\n",
      "epoch [95/100], loss: -0.06631985772401094\n",
      "epoch [96/100], loss: -0.06460198620334268\n",
      "epoch [97/100], loss: -0.060713604325428605\n",
      "epoch [98/100], loss: -0.06786413723602891\n",
      "epoch [99/100], loss: -0.0699692745693028\n",
      "epoch [100/100], loss: -0.0673332647420466\n",
      "torch.Size([502, 1]) 502\n",
      "len des rdt 1510\n",
      "len des dates 1510\n",
      "epoch [1/100], loss: -0.015654373419238254\n",
      "epoch [2/100], loss: -0.01618666315334849\n",
      "epoch [3/100], loss: -0.018214418887509964\n",
      "epoch [4/100], loss: -0.02339777338784188\n",
      "epoch [5/100], loss: -0.029664730885997415\n",
      "epoch [6/100], loss: -0.03107172856107354\n",
      "epoch [7/100], loss: -0.03389211418107152\n",
      "epoch [8/100], loss: -0.03636264684610069\n",
      "epoch [9/100], loss: -0.03791616135276854\n",
      "epoch [10/100], loss: -0.03928332217037678\n",
      "epoch [11/100], loss: -0.040503958240151405\n",
      "epoch [12/100], loss: -0.040982722071930766\n",
      "epoch [13/100], loss: -0.04186219675466418\n",
      "epoch [14/100], loss: -0.04220085055567324\n",
      "epoch [15/100], loss: -0.04125196090899408\n",
      "epoch [16/100], loss: -0.04319688118994236\n",
      "epoch [17/100], loss: -0.04341496992856264\n",
      "epoch [18/100], loss: -0.045044886879622936\n",
      "epoch [19/100], loss: -0.044185364386066794\n",
      "epoch [20/100], loss: -0.043835164280608296\n",
      "epoch [21/100], loss: -0.045312324771657586\n",
      "epoch [22/100], loss: -0.048135086661204696\n",
      "epoch [23/100], loss: -0.048629438038915396\n",
      "epoch [24/100], loss: -0.04860281432047486\n",
      "epoch [25/100], loss: -0.04808015422895551\n",
      "epoch [26/100], loss: -0.04816893767565489\n",
      "epoch [27/100], loss: -0.04872201127000153\n",
      "epoch [28/100], loss: -0.0446718221064657\n",
      "epoch [29/100], loss: -0.039272736525163054\n",
      "epoch [30/100], loss: -0.040011742850765586\n",
      "epoch [31/100], loss: -0.047737605636939406\n",
      "epoch [32/100], loss: -0.04856783011928201\n",
      "epoch [33/100], loss: -0.05096375849097967\n",
      "epoch [34/100], loss: -0.05062050744891167\n",
      "epoch [35/100], loss: -0.05173712130635977\n",
      "epoch [36/100], loss: -0.052543767960742116\n",
      "epoch [37/100], loss: -0.05401788139715791\n",
      "epoch [38/100], loss: -0.053844697773456573\n",
      "epoch [39/100], loss: -0.053443222772330046\n",
      "epoch [40/100], loss: -0.05030431295745075\n",
      "epoch [41/100], loss: -0.05425625015050173\n",
      "epoch [42/100], loss: -0.054933495819568634\n",
      "epoch [43/100], loss: -0.0550488845910877\n",
      "epoch [44/100], loss: -0.05056858574971557\n",
      "epoch [45/100], loss: -0.055921297054737806\n",
      "epoch [46/100], loss: -0.05453450931236148\n",
      "epoch [47/100], loss: -0.05550877470523119\n",
      "epoch [48/100], loss: -0.0598170030862093\n",
      "epoch [49/100], loss: -0.05737691931426525\n",
      "epoch [50/100], loss: -0.0524990672711283\n",
      "epoch [51/100], loss: -0.057572973892092705\n",
      "epoch [52/100], loss: -0.056006448809057474\n",
      "epoch [53/100], loss: -0.054321834817528725\n",
      "epoch [54/100], loss: -0.051839671563357115\n",
      "epoch [55/100], loss: -0.05755911860615015\n",
      "epoch [56/100], loss: -0.058526413049548864\n",
      "epoch [57/100], loss: -0.05778430635109544\n",
      "epoch [58/100], loss: -0.05924584390595555\n",
      "epoch [59/100], loss: -0.06154453381896019\n",
      "epoch [60/100], loss: -0.06020089611411095\n",
      "epoch [61/100], loss: -0.06165261287242174\n",
      "epoch [62/100], loss: -0.06314251944422722\n",
      "epoch [63/100], loss: -0.059430074179545045\n",
      "epoch [64/100], loss: -0.05726712290197611\n",
      "epoch [65/100], loss: -0.06448545306921005\n",
      "epoch [66/100], loss: -0.06181655451655388\n",
      "epoch [67/100], loss: -0.0647175800986588\n",
      "epoch [68/100], loss: -0.06525511434301734\n",
      "epoch [69/100], loss: -0.06756038265302777\n",
      "epoch [70/100], loss: -0.06865469692274928\n",
      "epoch [71/100], loss: -0.06347026536241174\n",
      "epoch [72/100], loss: -0.06326996814459562\n",
      "epoch [73/100], loss: -0.06420521484687924\n",
      "epoch [74/100], loss: -0.06715517491102219\n",
      "epoch [75/100], loss: -0.07018086733296514\n",
      "epoch [76/100], loss: -0.07114872615784407\n",
      "epoch [77/100], loss: -0.07041190098971128\n",
      "epoch [78/100], loss: -0.07125691650435328\n",
      "epoch [79/100], loss: -0.06853053020313382\n",
      "epoch [80/100], loss: -0.07006456237286329\n",
      "epoch [81/100], loss: -0.0730445496737957\n",
      "epoch [82/100], loss: -0.07107677031308413\n",
      "epoch [83/100], loss: -0.06712708901613951\n",
      "epoch [84/100], loss: -0.07249572686851025\n",
      "epoch [85/100], loss: -0.07319355476647615\n",
      "epoch [86/100], loss: -0.07324096839874983\n",
      "epoch [87/100], loss: -0.07574227126315236\n",
      "epoch [88/100], loss: -0.07418708875775337\n",
      "epoch [89/100], loss: -0.07081932108849287\n",
      "epoch [90/100], loss: -0.0760347293689847\n",
      "epoch [91/100], loss: -0.07702989550307393\n",
      "epoch [92/100], loss: -0.07809394178912044\n",
      "epoch [93/100], loss: -0.07430546497926116\n",
      "epoch [94/100], loss: -0.07290631392970681\n",
      "epoch [95/100], loss: -0.0734750758856535\n",
      "epoch [96/100], loss: -0.07359519880264997\n",
      "epoch [97/100], loss: -0.07510507199913263\n",
      "epoch [98/100], loss: -0.07409334322437644\n",
      "epoch [99/100], loss: -0.07323432480916381\n",
      "epoch [100/100], loss: -0.06800218345597386\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 2013\n",
      "len des dates 2013\n",
      "epoch [1/100], loss: -0.026702635339461267\n",
      "epoch [2/100], loss: -0.015345889536547475\n",
      "epoch [3/100], loss: -0.02376395184546709\n",
      "epoch [4/100], loss: -0.029650797019712627\n",
      "epoch [5/100], loss: -0.037308506085537374\n",
      "epoch [6/100], loss: -0.03848865791223943\n",
      "epoch [7/100], loss: -0.04319160268642008\n",
      "epoch [8/100], loss: -0.045138402841985226\n",
      "epoch [9/100], loss: -0.04611004330217838\n",
      "epoch [10/100], loss: -0.04686269094236195\n",
      "epoch [11/100], loss: -0.04832938173785806\n",
      "epoch [12/100], loss: -0.050467269495129585\n",
      "epoch [13/100], loss: -0.05208204034715891\n",
      "epoch [14/100], loss: -0.05324324406683445\n",
      "epoch [15/100], loss: -0.055042915511876345\n",
      "epoch [16/100], loss: -0.05381847685202956\n",
      "epoch [17/100], loss: -0.05288089020177722\n",
      "epoch [18/100], loss: -0.05198995862156153\n",
      "epoch [19/100], loss: -0.05419586831703782\n",
      "epoch [20/100], loss: -0.05268676392734051\n",
      "epoch [21/100], loss: -0.05334086436778307\n",
      "epoch [22/100], loss: -0.05482470104470849\n",
      "epoch [23/100], loss: -0.05820677103474736\n",
      "epoch [24/100], loss: -0.05903794523328543\n",
      "epoch [25/100], loss: -0.05970377707853913\n",
      "epoch [26/100], loss: -0.06172787398099899\n",
      "epoch [27/100], loss: -0.06212824769318104\n",
      "epoch [28/100], loss: -0.06347087165340781\n",
      "epoch [29/100], loss: -0.06454953970387578\n",
      "epoch [30/100], loss: -0.06585920322686434\n",
      "epoch [31/100], loss: -0.06594765093177557\n",
      "epoch [32/100], loss: -0.06622656295076013\n",
      "epoch [33/100], loss: -0.06502409745007753\n",
      "epoch [34/100], loss: -0.06590560358017683\n",
      "epoch [35/100], loss: -0.0647549876011908\n",
      "epoch [36/100], loss: -0.06593071203678846\n",
      "epoch [37/100], loss: -0.06736903637647629\n",
      "epoch [38/100], loss: -0.06481355940923095\n",
      "epoch [39/100], loss: -0.06199022615328431\n",
      "epoch [40/100], loss: -0.06114928377792239\n",
      "epoch [41/100], loss: -0.06631231168285012\n",
      "epoch [42/100], loss: -0.06484837085008621\n",
      "epoch [43/100], loss: -0.06910709338262677\n",
      "epoch [44/100], loss: -0.06838145479559898\n",
      "epoch [45/100], loss: -0.06222694832831621\n",
      "epoch [46/100], loss: -0.06304386397823691\n",
      "epoch [47/100], loss: -0.0652824086137116\n",
      "epoch [48/100], loss: -0.06889606546610594\n",
      "epoch [49/100], loss: -0.0702558932825923\n",
      "epoch [50/100], loss: -0.07188262417912483\n",
      "epoch [51/100], loss: -0.06950002582743764\n",
      "epoch [52/100], loss: -0.06891113379970193\n",
      "epoch [53/100], loss: -0.07018119376152754\n",
      "epoch [54/100], loss: -0.07074809866026044\n",
      "epoch [55/100], loss: -0.07161598140373826\n",
      "epoch [56/100], loss: -0.07541025429964066\n",
      "epoch [57/100], loss: -0.07577194599434733\n",
      "epoch [58/100], loss: -0.07222708454355597\n",
      "epoch [59/100], loss: -0.0732394359074533\n",
      "epoch [60/100], loss: -0.0655961912125349\n",
      "epoch [61/100], loss: -0.05375506612472236\n",
      "epoch [62/100], loss: -0.06174685014411807\n",
      "epoch [63/100], loss: -0.0705845351330936\n",
      "epoch [64/100], loss: -0.0707663930952549\n",
      "epoch [65/100], loss: -0.06902029272168875\n",
      "epoch [66/100], loss: -0.0738820880651474\n",
      "epoch [67/100], loss: -0.07315442431718111\n",
      "epoch [68/100], loss: -0.06696824124082923\n",
      "epoch [69/100], loss: -0.06865337118506432\n",
      "epoch [70/100], loss: -0.0593424066901207\n",
      "epoch [71/100], loss: -0.06428425759077072\n",
      "epoch [72/100], loss: -0.07130569266155362\n",
      "epoch [73/100], loss: -0.07478855177760124\n",
      "epoch [74/100], loss: -0.07721039839088917\n",
      "epoch [75/100], loss: -0.07870048331096768\n",
      "epoch [76/100], loss: -0.07112510222941637\n",
      "epoch [77/100], loss: -0.07599019259214401\n",
      "epoch [78/100], loss: -0.07325873896479607\n",
      "epoch [79/100], loss: -0.07064937520772219\n",
      "epoch [80/100], loss: -0.07490141037851572\n",
      "epoch [81/100], loss: -0.06899965833872557\n",
      "epoch [82/100], loss: -0.07743800152093172\n",
      "epoch [83/100], loss: -0.07871277816593647\n",
      "epoch [84/100], loss: -0.07991992775350809\n",
      "epoch [85/100], loss: -0.07624374143779278\n",
      "epoch [86/100], loss: -0.07484038127586246\n",
      "epoch [87/100], loss: -0.07644727593287826\n",
      "epoch [88/100], loss: -0.07086955336853862\n",
      "epoch [89/100], loss: -0.07690308755263686\n",
      "epoch [90/100], loss: -0.07791520841419697\n",
      "epoch [91/100], loss: -0.07459210557863116\n",
      "epoch [92/100], loss: -0.07888607075437903\n",
      "epoch [93/100], loss: -0.08158438373357058\n",
      "epoch [94/100], loss: -0.0731225716881454\n",
      "epoch [95/100], loss: -0.0773217617534101\n",
      "epoch [96/100], loss: -0.07735399482771754\n",
      "epoch [97/100], loss: -0.0766979088075459\n",
      "epoch [98/100], loss: -0.08262894209474325\n",
      "epoch [99/100], loss: -0.08357476396486163\n",
      "epoch [100/100], loss: -0.07945311162620783\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 2516\n",
      "len des dates 2516\n",
      "epoch [1/100], loss: -0.02339300262974575\n",
      "epoch [2/100], loss: -0.037206568755209446\n",
      "epoch [3/100], loss: -0.03967098635621369\n",
      "epoch [4/100], loss: -0.04781063902191818\n",
      "epoch [5/100], loss: -0.05179605074226856\n",
      "epoch [6/100], loss: -0.0532468359451741\n",
      "epoch [7/100], loss: -0.05578559823334217\n",
      "epoch [8/100], loss: -0.05753657408058643\n",
      "epoch [9/100], loss: -0.05742916511371732\n",
      "epoch [10/100], loss: -0.05552534107118845\n",
      "epoch [11/100], loss: -0.05931066256016493\n",
      "epoch [12/100], loss: -0.060325381346046925\n",
      "epoch [13/100], loss: -0.061225553043186665\n",
      "epoch [14/100], loss: -0.0626215972006321\n",
      "epoch [15/100], loss: -0.06392109068110585\n",
      "epoch [16/100], loss: -0.06389293959364295\n",
      "epoch [17/100], loss: -0.06642226641997695\n",
      "epoch [18/100], loss: -0.0670568235218525\n",
      "epoch [19/100], loss: -0.06811258848756552\n",
      "epoch [20/100], loss: -0.06805842416360974\n",
      "epoch [21/100], loss: -0.06635716883465648\n",
      "epoch [22/100], loss: -0.06846274854615331\n",
      "epoch [23/100], loss: -0.06895711785182357\n",
      "epoch [24/100], loss: -0.06865180842578411\n",
      "epoch [25/100], loss: -0.07052846346050501\n",
      "epoch [26/100], loss: -0.06970065925270319\n",
      "epoch [27/100], loss: -0.07025442598387599\n",
      "epoch [28/100], loss: -0.07258045300841331\n",
      "epoch [29/100], loss: -0.07187415100634098\n",
      "epoch [30/100], loss: -0.07082917680963874\n",
      "epoch [31/100], loss: -0.0705703990533948\n",
      "epoch [32/100], loss: -0.06883075227960944\n",
      "epoch [33/100], loss: -0.06418593972921371\n",
      "epoch [34/100], loss: -0.07073166640475392\n",
      "epoch [35/100], loss: -0.0740986755117774\n",
      "epoch [36/100], loss: -0.07385470811277628\n",
      "epoch [37/100], loss: -0.07415427500382066\n",
      "epoch [38/100], loss: -0.07431035442277789\n",
      "epoch [39/100], loss: -0.07014823146164417\n",
      "epoch [40/100], loss: -0.06936154142022133\n",
      "epoch [41/100], loss: -0.06497491104528308\n",
      "epoch [42/100], loss: -0.07138374587520957\n",
      "epoch [43/100], loss: -0.07228784309700131\n",
      "epoch [44/100], loss: -0.07507254183292389\n",
      "epoch [45/100], loss: -0.07510707108303905\n",
      "epoch [46/100], loss: -0.07776582753285766\n",
      "epoch [47/100], loss: -0.07794343214482069\n",
      "epoch [48/100], loss: -0.07972724689170718\n",
      "epoch [49/100], loss: -0.07703425968065858\n",
      "epoch [50/100], loss: -0.07474804576486349\n",
      "epoch [51/100], loss: -0.07649800693616271\n",
      "epoch [52/100], loss: -0.07868022052571177\n",
      "epoch [53/100], loss: -0.07726791501045227\n",
      "epoch [54/100], loss: -0.07474696589633822\n",
      "epoch [55/100], loss: -0.07440195512026548\n",
      "epoch [56/100], loss: -0.0781689528375864\n",
      "epoch [57/100], loss: -0.07835467765107751\n",
      "epoch [58/100], loss: -0.07373378332704306\n",
      "epoch [59/100], loss: -0.07006156770512462\n",
      "epoch [60/100], loss: -0.07653797836974263\n",
      "epoch [61/100], loss: -0.077827506698668\n",
      "epoch [62/100], loss: -0.07584073627367616\n",
      "epoch [63/100], loss: -0.07074059825390577\n",
      "epoch [64/100], loss: -0.0777659323066473\n",
      "epoch [65/100], loss: -0.0783962314017117\n",
      "epoch [66/100], loss: -0.07745305029675364\n",
      "epoch [67/100], loss: -0.08057701773941517\n",
      "epoch [68/100], loss: -0.08000090904533863\n",
      "epoch [69/100], loss: -0.08054753812029958\n",
      "epoch [70/100], loss: -0.07150317775085568\n",
      "epoch [71/100], loss: -0.08029092894867063\n",
      "epoch [72/100], loss: -0.07653978560119867\n",
      "epoch [73/100], loss: -0.07599453954026103\n",
      "epoch [74/100], loss: -0.08029606146737933\n",
      "epoch [75/100], loss: -0.07962942449375987\n",
      "epoch [76/100], loss: -0.08099529473111033\n",
      "epoch [77/100], loss: -0.08075134642422199\n",
      "epoch [78/100], loss: -0.08116141986101866\n",
      "epoch [79/100], loss: -0.08342962805181742\n",
      "epoch [80/100], loss: -0.08105177711695433\n",
      "epoch [81/100], loss: -0.07963001681491733\n",
      "epoch [82/100], loss: -0.08359148073941469\n",
      "epoch [83/100], loss: -0.08593788836151361\n",
      "epoch [84/100], loss: -0.08395953755825758\n",
      "epoch [85/100], loss: -0.08265232527628541\n",
      "epoch [86/100], loss: -0.08362875040620565\n",
      "epoch [87/100], loss: -0.07888894202187657\n",
      "epoch [88/100], loss: -0.07927180686965585\n",
      "epoch [89/100], loss: -0.07926032925024629\n",
      "epoch [90/100], loss: -0.07804850349202752\n",
      "epoch [91/100], loss: -0.08353855507448316\n",
      "epoch [92/100], loss: -0.08262838702648878\n",
      "epoch [93/100], loss: -0.08520231582224369\n",
      "epoch [94/100], loss: -0.08558657672256231\n",
      "epoch [95/100], loss: -0.08813660824671388\n",
      "epoch [96/100], loss: -0.08699655858799815\n",
      "epoch [97/100], loss: -0.08563785348087549\n",
      "epoch [98/100], loss: -0.08420835388824344\n",
      "epoch [99/100], loss: -0.08514388557523489\n",
      "epoch [100/100], loss: -0.08531827386468649\n",
      "torch.Size([179, 1]) 179\n",
      "len des rdt 2695\n",
      "len des dates 2695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdt_all = first_rdt\n",
    "alloc_all = first_alloc\n",
    "\n",
    "#entrainement sur 5 cycles Cycle 1 :\n",
    "#Période d’entraînement : 2006 à 2010.\n",
    "#Période d’investissement : 2010 à 2012.\n",
    "#Cycle 2 :\n",
    "#La date de fin d’entraînement est avancée jusqu'en 2012 (couvrant 2006-2012).\n",
    "#La nouvelle période d’investissement couvre alors 2012 à 2014.\n",
    "#etc jusqu'au cycle 5 \n",
    "#rdt_all/alloc_all contient les rendements/alloc sur toute la période \n",
    "\n",
    "#change tp 4\n",
    "for i in range(5):\n",
    "\n",
    "    model = training(x_batches = x_batches[idx_start_invest:idx_end_invest, :, :],\n",
    "                      y_batches= y_batches[idx_start_invest:idx_end_invest, :, :],\n",
    "                      model=model,\n",
    "                      batch_size=64)\n",
    "    \n",
    "    date_end_invest = date_end_invest + datetime.timedelta(days=365*2)\n",
    "    end_date_1st_training = end_date_1st_training + datetime.timedelta(days=365*2)\n",
    "    idx_start_invest, idx_end_invest = get_idx_dates(end_date_1st_training, date_end_invest)\n",
    "\n",
    "    x_investing = x_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "    y_investing = y_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "    y_real = y[idx_start_invest:idx_end_invest, :, :]\n",
    "\n",
    "\n",
    "    first_rdt, first_alloc = investing(x_batches= x_investing, y=y_real, model=model)\n",
    "\n",
    "    print(first_rdt.shape, len(dates_per_feature[idx_start_invest:idx_end_invest]))\n",
    "\n",
    "\n",
    "    rdt_all = torch.cat([rdt_all, first_rdt], dim=0)\n",
    "    print('len des rdt', rdt_all.shape[0])\n",
    "    alloc_all = torch.cat([alloc_all, first_alloc], dim=0)\n",
    "    idx_invest.append((idx_start_invest, idx_end_invest))\n",
    "    print('len des dates', len(dates_per_feature[idx_invest[0][0]:idx_invest[-1][1]]))\n",
    "    dates_invest.append((end_date_1st_training, date_end_invest))\n",
    "\n",
    "\n",
    "alloc_all = alloc_all.numpy()\n",
    "alloc_all = alloc_all.reshape(alloc_all.shape[0], alloc_all.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\2977585624.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na['Date'] = pd.to_datetime(data_na['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Return</th>\n",
       "      <th>Alloc_AGG</th>\n",
       "      <th>Alloc_DBC</th>\n",
       "      <th>Alloc_VTI</th>\n",
       "      <th>Alloc_^VIX</th>\n",
       "      <th>AGG_y</th>\n",
       "      <th>DBC_y</th>\n",
       "      <th>VTI_y</th>\n",
       "      <th>^VIX_y</th>\n",
       "      <th>Final_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.552563</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.407883</td>\n",
       "      <td>0.036454</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>-0.092849</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.769451</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.211385</td>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.808225</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.148870</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-22</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.663633</td>\n",
       "      <td>0.184221</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.006023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-23</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.272422</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.651372</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.004904</td>\n",
       "      <td>-0.003521</td>\n",
       "      <td>0.051143</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.958990</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>-0.037969</td>\n",
       "      <td>-0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.970023</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.076362</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.874259</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.108709</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.948678</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.037697</td>\n",
       "      <td>0.013318</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.063594</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>0.000553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2695 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Return  Alloc_AGG  Alloc_DBC  Alloc_VTI  Alloc_^VIX  \\\n",
       "0    2010-04-19  0.001405   0.552563   0.003101   0.407883    0.036454   \n",
       "1    2010-04-20  0.001786   0.769451   0.002737   0.211385    0.016427   \n",
       "2    2010-04-21 -0.000540   0.808225   0.005197   0.148870    0.037709   \n",
       "3    2010-04-22  0.006023   0.146700   0.005446   0.663633    0.184221   \n",
       "4    2010-04-23  0.001346   0.272422   0.004133   0.651372    0.072072   \n",
       "...         ...       ...        ...        ...        ...         ...   \n",
       "2690 2020-12-22 -0.000645   0.958990   0.001089   0.037993    0.001928   \n",
       "2691 2020-12-23  0.000713   0.970023   0.000880   0.025979    0.003118   \n",
       "2692 2020-12-24  0.000934   0.874259   0.002577   0.108709    0.014454   \n",
       "2693 2020-12-28  0.000851   0.948678   0.000308   0.037697    0.013318   \n",
       "2694 2020-12-29  0.000553   0.990879   0.000105   0.005314    0.003702   \n",
       "\n",
       "         AGG_y     DBC_y     VTI_y    ^VIX_y  Final_Return  \n",
       "0     0.001631  0.007936  0.009474 -0.092849      0.001405  \n",
       "1     0.001724  0.004973 -0.000809  0.037508      0.001786  \n",
       "2    -0.002008  0.002474  0.004858  0.009191     -0.000540  \n",
       "3    -0.001246  0.006582  0.006769  0.009108      0.006023  \n",
       "4    -0.000096 -0.004904 -0.003521  0.051143      0.001346  \n",
       "...        ...       ...       ...       ...           ...  \n",
       "2690 -0.000678  0.012517  0.001710 -0.037969     -0.000645  \n",
       "2691  0.000933  0.002747  0.001673 -0.076362      0.000713  \n",
       "2692  0.000170 -0.006164  0.006327  0.007896      0.000934  \n",
       "2693  0.000169  0.002757 -0.004174  0.063594      0.000851  \n",
       "2694  0.000593  0.006186  0.002691 -0.013432      0.000553  \n",
       "\n",
       "[2695 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe_result = pd.DataFrame({\n",
    "    'Date': pd.Series(dates_per_feature[idx_invest[0][0]:idx_invest[-1][1]]),\n",
    "    'Return': pd.Series(rdt_all.numpy().flatten()),\n",
    "    'Alloc_AGG': pd.Series(alloc_all[:, 0]),\n",
    "    'Alloc_DBC': pd.Series(alloc_all[:, 1]),\n",
    "    'Alloc_VTI': pd.Series(alloc_all[:, 2]),\n",
    "    'Alloc_^VIX': pd.Series(alloc_all[:, 3])\n",
    "})\n",
    "\n",
    "dataframe_result['Date'] = pd.to_datetime(dataframe_result['Date'])\n",
    "data_na['Date'] = pd.to_datetime(data_na['Date'])\n",
    "dataframe_result = pd.merge(dataframe_result, data_na[['Date', 'AGG_y', 'DBC_y', 'VTI_y', '^VIX_y']], on='Date', how='left')\n",
    "\n",
    "dataframe_result['Final_Return'] = (\n",
    "    dataframe_result['Alloc_AGG'] * dataframe_result['AGG_y'] +\n",
    "    dataframe_result['Alloc_DBC'] * dataframe_result['DBC_y'] +\n",
    "    dataframe_result['Alloc_VTI'] * dataframe_result['VTI_y'] +\n",
    "    dataframe_result['Alloc_^VIX'] * dataframe_result['^VIX_y']\n",
    ")\n",
    "\n",
    "dataframe_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annualized mean return: 0.3455\n",
      "annualized std: 0.2630\n",
      "annualized dd: 0.1250\n",
      "Sharpe Ratio: 1.3138\n",
      "Sortino Ratio: 2.7634\n"
     ]
    }
   ],
   "source": [
    "trading_days_per_year = 252\n",
    "\n",
    "mean_daily_return = dataframe_result['Final_Return'].mean()\n",
    "annualized_return = (1+mean_daily_return) ** trading_days_per_year -1\n",
    "\n",
    "std_daily_return = dataframe_result['Final_Return'].std()\n",
    "std_dd_return = dataframe_result[dataframe_result['Final_Return'] < 0]['Final_Return'].std()\n",
    "\n",
    "annualized_volatility = std_daily_return * np.sqrt(trading_days_per_year)\n",
    "annualized_volatility_dd = std_dd_return * np.sqrt(trading_days_per_year)\n",
    "\n",
    "sharpe_ratio = annualized_return / annualized_volatility\n",
    "sortino_ratio = annualized_return / annualized_volatility_dd\n",
    "\n",
    "print(f\"annualized mean return: {annualized_return:.4f}\")\n",
    "print(f\"annualized std: {annualized_volatility:.4f}\")\n",
    "print(f\"annualized dd: {annualized_volatility_dd:.4f}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "print(f\"Sortino Ratio: {sortino_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_volatility(x_batches, decay=0.94):\n",
    "    \"\"\"\n",
    "    Calculate the ex-ante volatility for each asset in each window in x_batches\n",
    "    using an exponentially weighted moving standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_batches: torch.Tensor of shape (num_windows, window_size, num_features)\n",
    "    - decay: float, decay factor for exponential weighting (e.g., 0.94)\n",
    "    \n",
    "    Returns:\n",
    "    - volatilities: torch.Tensor of shape (num_windows, num_assets)\n",
    "    \"\"\"\n",
    "    # Extract only the return columns; x_batches has shape (num_windows, window_size=50, num_features=8)\n",
    "    returns_batches = x_batches[:, :, :x_batches.shape[2] // 2]\n",
    "    window_size = returns_batches.shape[1]\n",
    "    num_assets = returns_batches.shape[2]\n",
    "    \n",
    "    weights = torch.tensor([decay ** i for i in range(window_size - 1, -1, -1)], dtype=torch.float32)\n",
    "    weights /= weights.sum()  \n",
    "    \n",
    "    volatilities = []\n",
    "    for window in returns_batches:\n",
    "        window_tensor = torch.tensor(window, dtype=torch.float32)  # Convert `window` to a tensor\n",
    "        weighted_returns = window_tensor * weights.view(-1, 1)  # Apply weights\n",
    "        mean_weighted = weighted_returns.sum(dim=0)  # Weighted mean for each asset\n",
    "        variance_weighted = ((window_tensor - mean_weighted) ** 2 * weights.view(-1, 1)).sum(dim=0)\n",
    "        std_weighted = torch.sqrt(variance_weighted)\n",
    "        volatilities.append(std_weighted)\n",
    "    \n",
    "    # Stack for all windows\n",
    "    volatilities = torch.stack(volatilities)\n",
    "    return volatilities  # We have the volatilities at the final date for each 50-day window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investing_scaled(x_batches, y, model, volatilities, target_volatility=0.1, cost_rate=0.0001): \n",
    "    \"\"\"\n",
    "    Calculates the portfolio returns using model allocations, adjusted by volatility scaling and transaction costs.\n",
    "\n",
    "    Parameters:\n",
    "    - x_batches: np.array, shape (num_batches, window_size, input_size), input data (returns and prices).\n",
    "    - y: np.array, shape (num_batches, 1, num_assets), target returns for each day in the investing period.\n",
    "    - model: trained model for generating portfolio allocations.\n",
    "    - volatilities: np.array, shape (num_batches, num_assets), ex-ante volatilities for each asset.\n",
    "    - target_volatility: float, target volatility level.\n",
    "    - cost_rate: float, transaction cost rate.\n",
    "\n",
    "    Returns:\n",
    "    - portfolio_returns: Tensor, shape (num_batches, 1), calculated portfolio returns.\n",
    "    - allocations: Tensor, shape (num_batches, num_assets), model's allocations for each asset.\n",
    "    \"\"\"\n",
    "    x_tensor = torch.tensor(x_batches, dtype=torch.float32)\n",
    "    allocations = model.get_allocations(x_tensor)  # Shape: (num_batches, num_assets)\n",
    "\n",
    "    allocations = allocations.view(allocations.shape[0], 1, allocations.shape[1])\n",
    "    \n",
    "    volatilities = torch.tensor(volatilities, dtype=torch.float32)\n",
    "    \n",
    "    scaling_factor = target_volatility / volatilities  # Shape: (num_batches, num_assets)\n",
    "    scaled_allocations = allocations * scaling_factor.unsqueeze(1) \n",
    "\n",
    "    # on décale de 1 à la prem dimension car c celle du temps \n",
    "    transaction_costs = cost_rate * torch.sum(torch.abs(scaled_allocations[1:] - scaled_allocations[:-1]), dim=2)\n",
    "\n",
    "\n",
    "    portfolio_returns = torch.sum(scaled_allocations * y, dim=2)\n",
    "    portfolio_returns[1:] -= transaction_costs  # Apply transaction costs from the second time step onward\n",
    "\n",
    "    return portfolio_returns, scaled_allocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: -0.025247834506444633\n",
      "epoch [2/100], loss: -0.03462966068764217\n",
      "epoch [3/100], loss: -0.03978791073313914\n",
      "epoch [4/100], loss: -0.03442962621920742\n",
      "epoch [5/100], loss: -0.03988870786270127\n",
      "epoch [6/100], loss: -0.035906557575799525\n",
      "epoch [7/100], loss: -0.04351254637003876\n",
      "epoch [8/100], loss: -0.03881423383427318\n",
      "epoch [9/100], loss: -0.04347448970656842\n",
      "epoch [10/100], loss: -0.04298895166721195\n",
      "epoch [11/100], loss: -0.046827532758470625\n",
      "epoch [12/100], loss: -0.046222640994528774\n",
      "epoch [13/100], loss: -0.04213450910174288\n",
      "epoch [14/100], loss: -0.05186720700294245\n",
      "epoch [15/100], loss: -0.05302463566476945\n",
      "epoch [16/100], loss: -0.05362520504422719\n",
      "epoch [17/100], loss: -0.0550864093893324\n",
      "epoch [18/100], loss: -0.05650403333129361\n",
      "epoch [19/100], loss: -0.05540634581120685\n",
      "epoch [20/100], loss: -0.05359545738610905\n",
      "epoch [21/100], loss: -0.049116382768261246\n",
      "epoch [22/100], loss: -0.04435647831269307\n",
      "epoch [23/100], loss: -0.05404937075218186\n",
      "epoch [24/100], loss: -0.05524760301341303\n",
      "epoch [25/100], loss: -0.060048365688999183\n",
      "epoch [26/100], loss: -0.0600677914917469\n",
      "epoch [27/100], loss: -0.060046191516448744\n",
      "epoch [28/100], loss: -0.05904719635145739\n",
      "epoch [29/100], loss: -0.05919042314053513\n",
      "epoch [30/100], loss: -0.04446727462345734\n",
      "epoch [31/100], loss: -0.05810469016432762\n",
      "epoch [32/100], loss: -0.06161190435523167\n",
      "epoch [33/100], loss: -0.06089460849761963\n",
      "epoch [34/100], loss: -0.06193148228339851\n",
      "epoch [35/100], loss: -0.06449076457647607\n",
      "epoch [36/100], loss: -0.06403706560377032\n",
      "epoch [37/100], loss: -0.06451094575459138\n",
      "epoch [38/100], loss: -0.0639749652473256\n",
      "epoch [39/100], loss: -0.057858617044985294\n",
      "epoch [40/100], loss: -0.06689611275214702\n",
      "epoch [41/100], loss: -0.0645922685507685\n",
      "epoch [42/100], loss: -0.06549902039114386\n",
      "epoch [43/100], loss: -0.06727032037451863\n",
      "epoch [44/100], loss: -0.060505150409881026\n",
      "epoch [45/100], loss: -0.06212190946098417\n",
      "epoch [46/100], loss: -0.0591285543050617\n",
      "epoch [47/100], loss: -0.06381710240384564\n",
      "epoch [48/100], loss: -0.06322491931496188\n",
      "epoch [49/100], loss: -0.062441663118079305\n",
      "epoch [50/100], loss: -0.057236547116190195\n",
      "epoch [51/100], loss: -0.06758516415720806\n",
      "epoch [52/100], loss: -0.06591057300101966\n",
      "epoch [53/100], loss: -0.0695141067262739\n",
      "epoch [54/100], loss: -0.07012970501091331\n",
      "epoch [55/100], loss: -0.07276400038972497\n",
      "epoch [56/100], loss: -0.07364305458031595\n",
      "epoch [57/100], loss: -0.060163246700540185\n",
      "epoch [58/100], loss: -0.06165088800480589\n",
      "epoch [59/100], loss: -0.06234390812460333\n",
      "epoch [60/100], loss: -0.07095911621581763\n",
      "epoch [61/100], loss: -0.07403580425307155\n",
      "epoch [62/100], loss: -0.07518075965344906\n",
      "epoch [63/100], loss: -0.07470216392539442\n",
      "epoch [64/100], loss: -0.06280657462775707\n",
      "epoch [65/100], loss: -0.06804461008869112\n",
      "epoch [66/100], loss: -0.06668458308558911\n",
      "epoch [67/100], loss: -0.06473639304749668\n",
      "epoch [68/100], loss: -0.06041485338937491\n",
      "epoch [69/100], loss: -0.07665612490382046\n",
      "epoch [70/100], loss: -0.07360202528070658\n",
      "epoch [71/100], loss: -0.07815564912743866\n",
      "epoch [72/100], loss: -0.07451098307501525\n",
      "epoch [73/100], loss: -0.07679510023444891\n",
      "epoch [74/100], loss: -0.07533078524284065\n",
      "epoch [75/100], loss: -0.07182202278636396\n",
      "epoch [76/100], loss: -0.06929623440373689\n",
      "epoch [77/100], loss: -0.06771325279260054\n",
      "epoch [78/100], loss: -0.06994832248892635\n",
      "epoch [79/100], loss: -0.07429203577339649\n",
      "epoch [80/100], loss: -0.07487252866849303\n",
      "epoch [81/100], loss: -0.07388466049451381\n",
      "epoch [82/100], loss: -0.07460773724596947\n",
      "epoch [83/100], loss: -0.08104210183955729\n",
      "epoch [84/100], loss: -0.08407388348132372\n",
      "epoch [85/100], loss: -0.08507094788365066\n",
      "epoch [86/100], loss: -0.08163667842745781\n",
      "epoch [87/100], loss: -0.07833781105000526\n",
      "epoch [88/100], loss: -0.07975423021707684\n",
      "epoch [89/100], loss: -0.06404655624646693\n",
      "epoch [90/100], loss: -0.05474125815089792\n",
      "epoch [91/100], loss: -0.0690922272624448\n",
      "epoch [92/100], loss: -0.0669984290143475\n",
      "epoch [93/100], loss: -0.06785827339626849\n",
      "epoch [94/100], loss: -0.08070893818512559\n",
      "epoch [95/100], loss: -0.08532488974742591\n",
      "epoch [96/100], loss: -0.08072634332347661\n",
      "epoch [97/100], loss: -0.08320804894901812\n",
      "epoch [98/100], loss: -0.08688459370750934\n",
      "epoch [99/100], loss: -0.08360354602336884\n",
      "epoch [100/100], loss: -0.08994472038466483\n",
      "Idx start: 1005, Idx end: 1510\n",
      "2010-04-19 2012-04-18\n",
      "torch.Size([505, 1]) 505\n",
      "first_rdt shape: torch.Size([505, 1]), rdt_all shape before concat: torch.Size([0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\3173161383.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  volatilities = torch.tensor(volatilities, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "input_size = 8\n",
    "hidden_size = 64\n",
    "output_size = 4\n",
    "batch_size = 64\n",
    "\n",
    "rdt_all = torch.empty(0,0)\n",
    "alloc_all = []\n",
    "idx_invest = []\n",
    "dates_invest = []\n",
    "\n",
    "# first training goes from 2006 to 2010\n",
    "first_date = dates_per_feature[0]\n",
    "end_date_1st_training = first_date + datetime.timedelta(days=365*4)\n",
    "\n",
    "# trouve le premier batch et le dernier batch correspondant\n",
    "idx_start, idx_end = get_idx_dates(first_date, end_date_1st_training)\n",
    "\n",
    "model = PortfolioRNN(input_size=input_size, hidden_size=hidden_size, num_layers = 2,output_size=output_size)\n",
    "\n",
    "\n",
    "model = training(x_batches = x_batches[idx_start:idx_end, :, :],\n",
    "                      y_batches= y_batches[idx_start:idx_end, :, :],\n",
    "                      model=model,\n",
    "                      batch_size=64)\n",
    "\n",
    "# un an c pas 365 jours mais 252 jours de trading\n",
    "date_end_invest = end_date_1st_training + datetime.timedelta(days=365*2)\n",
    "idx_start_invest, idx_end_invest = get_idx_dates(end_date_1st_training, date_end_invest)\n",
    "\n",
    "print(f\"Idx start: {idx_start_invest}, Idx end: {idx_end_invest}\")\n",
    "print(dates_per_feature[idx_start_invest], dates_per_feature[idx_end_invest])\n",
    "\n",
    "idx_invest.append((idx_start_invest, idx_end_invest))\n",
    "dates_invest.append((end_date_1st_training, date_end_invest))\n",
    "\n",
    "x_investing = x_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "y_investing = y_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "y_real = y[idx_start_invest:idx_end_invest, :, :]\n",
    "\n",
    "#calcul des volatilités\n",
    "volatilities = calculate_volatility(x_batches=x_investing)\n",
    "\n",
    "first_rdt, first_alloc = investing_scaled(x_batches= x_investing, y=y_real, volatilities=volatilities, model=model)\n",
    "\n",
    "print(first_rdt.shape, len(dates_per_feature[idx_start_invest:idx_end_invest]))\n",
    "\n",
    "print(f\"first_rdt shape: {first_rdt.shape}, rdt_all shape before concat: {rdt_all.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: -0.027060609310865402\n",
      "epoch [2/100], loss: -0.03377311024814844\n",
      "epoch [3/100], loss: -0.036357807694002986\n",
      "epoch [4/100], loss: -0.037508981535211205\n",
      "epoch [5/100], loss: -0.038861619075760245\n",
      "epoch [6/100], loss: -0.039881942328065634\n",
      "epoch [7/100], loss: -0.041656311601400375\n",
      "epoch [8/100], loss: -0.04213876649737358\n",
      "epoch [9/100], loss: -0.04376630438491702\n",
      "epoch [10/100], loss: -0.045357906725257635\n",
      "epoch [11/100], loss: -0.046239478047937155\n",
      "epoch [12/100], loss: -0.047415432054549456\n",
      "epoch [13/100], loss: -0.04764600354246795\n",
      "epoch [14/100], loss: -0.04682529345154762\n",
      "epoch [15/100], loss: -0.04737794864922762\n",
      "epoch [16/100], loss: -0.04666434554383159\n",
      "epoch [17/100], loss: -0.04980685259215534\n",
      "epoch [18/100], loss: -0.049754428677260876\n",
      "epoch [19/100], loss: -0.050867271842435\n",
      "epoch [20/100], loss: -0.0483173334505409\n",
      "epoch [21/100], loss: -0.04487251280806959\n",
      "epoch [22/100], loss: -0.04765549302101135\n",
      "epoch [23/100], loss: -0.04486356978304684\n",
      "epoch [24/100], loss: -0.05019836011342704\n",
      "epoch [25/100], loss: -0.04744682786986232\n",
      "epoch [26/100], loss: -0.04514992516487837\n",
      "epoch [27/100], loss: -0.05291837523691356\n",
      "epoch [28/100], loss: -0.05458335159346461\n",
      "epoch [29/100], loss: -0.055148457642644644\n",
      "epoch [30/100], loss: -0.0553980462718755\n",
      "epoch [31/100], loss: -0.05651845270767808\n",
      "epoch [32/100], loss: -0.05433471594005823\n",
      "epoch [33/100], loss: -0.05642675212584436\n",
      "epoch [34/100], loss: -0.05527619435451925\n",
      "epoch [35/100], loss: -0.056229672860354185\n",
      "epoch [36/100], loss: -0.05671515827998519\n",
      "epoch [37/100], loss: -0.053298276383429766\n",
      "epoch [38/100], loss: -0.0472778060939163\n",
      "epoch [39/100], loss: -0.04472393775358796\n",
      "epoch [40/100], loss: -0.057506196200847626\n",
      "epoch [41/100], loss: -0.05785995116457343\n",
      "epoch [42/100], loss: -0.0611858363263309\n",
      "epoch [43/100], loss: -0.06269380310550332\n",
      "epoch [44/100], loss: -0.05868621030822396\n",
      "epoch [45/100], loss: -0.05579035868868232\n",
      "epoch [46/100], loss: -0.05540099507197738\n",
      "epoch [47/100], loss: -0.05368322227150202\n",
      "epoch [48/100], loss: -0.05748224048875272\n",
      "epoch [49/100], loss: -0.05953329335898161\n",
      "epoch [50/100], loss: -0.06432660482823849\n",
      "epoch [51/100], loss: -0.06241803476586938\n",
      "epoch [52/100], loss: -0.06113918451592326\n",
      "epoch [53/100], loss: -0.061177872121334076\n",
      "epoch [54/100], loss: -0.062129855155944824\n",
      "epoch [55/100], loss: -0.062496569473296404\n",
      "epoch [56/100], loss: -0.06686723604798317\n",
      "epoch [57/100], loss: -0.0663833194412291\n",
      "epoch [58/100], loss: -0.06701513892039657\n",
      "epoch [59/100], loss: -0.06753455335274339\n",
      "epoch [60/100], loss: -0.06659687357023358\n",
      "epoch [61/100], loss: -0.06946178479120135\n",
      "epoch [62/100], loss: -0.07145497854799032\n",
      "epoch [63/100], loss: -0.07303691329434514\n",
      "epoch [64/100], loss: -0.07279353449121118\n",
      "epoch [65/100], loss: -0.07242830749601126\n",
      "epoch [66/100], loss: -0.07031015772372484\n",
      "epoch [67/100], loss: -0.06973365927115083\n",
      "epoch [68/100], loss: -0.0677284081466496\n",
      "epoch [69/100], loss: -0.06743449810892344\n",
      "epoch [70/100], loss: -0.06434073345735669\n",
      "epoch [71/100], loss: -0.06741417292505503\n",
      "epoch [72/100], loss: -0.0715990699827671\n",
      "epoch [73/100], loss: -0.07309653097763658\n",
      "epoch [74/100], loss: -0.07598317647352815\n",
      "epoch [75/100], loss: -0.07632300676777959\n",
      "epoch [76/100], loss: -0.07708558440208435\n",
      "epoch [77/100], loss: -0.07207006216049194\n",
      "epoch [78/100], loss: -0.07682858500629663\n",
      "epoch [79/100], loss: -0.0746294017881155\n",
      "epoch [80/100], loss: -0.07369867712259293\n",
      "epoch [81/100], loss: -0.07367072859779\n",
      "epoch [82/100], loss: -0.06345193553715944\n",
      "epoch [83/100], loss: -0.07134196441620588\n",
      "epoch [84/100], loss: -0.07373634865507483\n",
      "epoch [85/100], loss: -0.07803781470283866\n",
      "epoch [86/100], loss: -0.07697038818150759\n",
      "epoch [87/100], loss: -0.0793588561937213\n",
      "epoch [88/100], loss: -0.08102711522951722\n",
      "epoch [89/100], loss: -0.08167554996907711\n",
      "epoch [90/100], loss: -0.08244863012805581\n",
      "epoch [91/100], loss: -0.08057055436074734\n",
      "epoch [92/100], loss: -0.08019471587613225\n",
      "epoch [93/100], loss: -0.08123587258160114\n",
      "epoch [94/100], loss: -0.08268825663253665\n",
      "epoch [95/100], loss: -0.0840461659245193\n",
      "epoch [96/100], loss: -0.0877748653292656\n",
      "epoch [97/100], loss: -0.08745504496619105\n",
      "epoch [98/100], loss: -0.08263832237571478\n",
      "epoch [99/100], loss: -0.0810410468839109\n",
      "epoch [100/100], loss: -0.06739640515297651\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 1008\n",
      "len des dates 1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\3173161383.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  volatilities = torch.tensor(volatilities, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss: -0.014108190167462453\n",
      "epoch [2/100], loss: -0.027856891276314855\n",
      "epoch [3/100], loss: -0.03222095454111695\n",
      "epoch [4/100], loss: -0.03262593410909176\n",
      "epoch [5/100], loss: -0.03791768755763769\n",
      "epoch [6/100], loss: -0.03951485990546644\n",
      "epoch [7/100], loss: -0.04032116383314133\n",
      "epoch [8/100], loss: -0.04280895437113941\n",
      "epoch [9/100], loss: -0.04388297419063747\n",
      "epoch [10/100], loss: -0.045038087759166956\n",
      "epoch [11/100], loss: -0.04564559133723378\n",
      "epoch [12/100], loss: -0.0461807104293257\n",
      "epoch [13/100], loss: -0.046416802098974586\n",
      "epoch [14/100], loss: -0.047229107236489654\n",
      "epoch [15/100], loss: -0.045946171041578054\n",
      "epoch [16/100], loss: -0.042000594548881054\n",
      "epoch [17/100], loss: -0.04086728685069829\n",
      "epoch [18/100], loss: -0.044985092943534255\n",
      "epoch [19/100], loss: -0.047675623558461666\n",
      "epoch [20/100], loss: -0.04949875548481941\n",
      "epoch [21/100], loss: -0.049709733575582504\n",
      "epoch [22/100], loss: -0.05006291624158621\n",
      "epoch [23/100], loss: -0.048559530172497034\n",
      "epoch [24/100], loss: -0.04843117296695709\n",
      "epoch [25/100], loss: -0.04709991067647934\n",
      "epoch [26/100], loss: -0.04431688622571528\n",
      "epoch [27/100], loss: -0.047802077839151025\n",
      "epoch [28/100], loss: -0.046462119556963444\n",
      "epoch [29/100], loss: -0.051543375477194786\n",
      "epoch [30/100], loss: -0.05233522318303585\n",
      "epoch [31/100], loss: -0.054171286057680845\n",
      "epoch [32/100], loss: -0.05549784703180194\n",
      "epoch [33/100], loss: -0.055193868931382895\n",
      "epoch [34/100], loss: -0.05306097958236933\n",
      "epoch [35/100], loss: -0.055258865002542734\n",
      "epoch [36/100], loss: -0.05767764197662473\n",
      "epoch [37/100], loss: -0.059713362250477076\n",
      "epoch [38/100], loss: -0.058101480826735497\n",
      "epoch [39/100], loss: -0.05598578997887671\n",
      "epoch [40/100], loss: -0.05541092483326793\n",
      "epoch [41/100], loss: -0.055344936437904835\n",
      "epoch [42/100], loss: -0.050814063753932714\n",
      "epoch [43/100], loss: -0.0550139551050961\n",
      "epoch [44/100], loss: -0.059872758109122515\n",
      "epoch [45/100], loss: -0.05777801340445876\n",
      "epoch [46/100], loss: -0.05754347052425146\n",
      "epoch [47/100], loss: -0.05294809816405177\n",
      "epoch [48/100], loss: -0.0499921552836895\n",
      "epoch [49/100], loss: -0.04939056024886668\n",
      "epoch [50/100], loss: -0.05122562078759074\n",
      "epoch [51/100], loss: -0.054863960947841406\n",
      "epoch [52/100], loss: -0.058023419231176376\n",
      "epoch [53/100], loss: -0.0591796743683517\n",
      "epoch [54/100], loss: -0.060335314366966486\n",
      "epoch [55/100], loss: -0.062428311444818974\n",
      "epoch [56/100], loss: -0.06188983377069235\n",
      "epoch [57/100], loss: -0.05980213452130556\n",
      "epoch [58/100], loss: -0.05853775795549154\n",
      "epoch [59/100], loss: -0.06482918560504913\n",
      "epoch [60/100], loss: -0.06532536679878831\n",
      "epoch [61/100], loss: -0.0664600427262485\n",
      "epoch [62/100], loss: -0.06349072232842445\n",
      "epoch [63/100], loss: -0.06818015268072486\n",
      "epoch [64/100], loss: -0.06692832102999091\n",
      "epoch [65/100], loss: -0.05789234349504113\n",
      "epoch [66/100], loss: -0.044852844439446926\n",
      "epoch [67/100], loss: -0.051251363940536976\n",
      "epoch [68/100], loss: -0.051495525520294905\n",
      "epoch [69/100], loss: -0.05359817133285105\n",
      "epoch [70/100], loss: -0.05507614417001605\n",
      "epoch [71/100], loss: -0.059779409784823656\n",
      "epoch [72/100], loss: -0.05711202137172222\n",
      "epoch [73/100], loss: -0.0570107395760715\n",
      "epoch [74/100], loss: -0.058699737302958965\n",
      "epoch [75/100], loss: -0.06024213368073106\n",
      "epoch [76/100], loss: -0.0597634338773787\n",
      "epoch [77/100], loss: -0.05837424797937274\n",
      "epoch [78/100], loss: -0.06324364803731441\n",
      "epoch [79/100], loss: -0.06567545980215073\n",
      "epoch [80/100], loss: -0.06425603805109859\n",
      "epoch [81/100], loss: -0.06612136214971542\n",
      "epoch [82/100], loss: -0.06403455045074224\n",
      "epoch [83/100], loss: -0.0681906514801085\n",
      "epoch [84/100], loss: -0.07017810130491853\n",
      "epoch [85/100], loss: -0.06475896574556828\n",
      "epoch [86/100], loss: -0.05710848793387413\n",
      "epoch [87/100], loss: -0.051614188589155674\n",
      "epoch [88/100], loss: -0.0606443309225142\n",
      "epoch [89/100], loss: -0.06563119497150183\n",
      "epoch [90/100], loss: -0.06985001638531685\n",
      "epoch [91/100], loss: -0.07188718253746629\n",
      "epoch [92/100], loss: -0.07318719336763024\n",
      "epoch [93/100], loss: -0.07340140733867884\n",
      "epoch [94/100], loss: -0.07028038147836924\n",
      "epoch [95/100], loss: -0.07052353117614985\n",
      "epoch [96/100], loss: -0.07003509718924761\n",
      "epoch [97/100], loss: -0.06781860254704952\n",
      "epoch [98/100], loss: -0.0695672370493412\n",
      "epoch [99/100], loss: -0.07110283570364118\n",
      "epoch [100/100], loss: -0.07443887088447809\n",
      "torch.Size([502, 1]) 502\n",
      "len des rdt 1510\n",
      "len des dates 1510\n",
      "epoch [1/100], loss: -0.015751736023958074\n",
      "epoch [2/100], loss: -0.02444357384229079\n",
      "epoch [3/100], loss: -0.021243882947601378\n",
      "epoch [4/100], loss: -0.026237251877319068\n",
      "epoch [5/100], loss: -0.02558951498940587\n",
      "epoch [6/100], loss: -0.02895985112991184\n",
      "epoch [7/100], loss: -0.033364016795530915\n",
      "epoch [8/100], loss: -0.03176653874106705\n",
      "epoch [9/100], loss: -0.03651697654277086\n",
      "epoch [10/100], loss: -0.03644862398505211\n",
      "epoch [11/100], loss: -0.04011944564990699\n",
      "epoch [12/100], loss: -0.03847544500604272\n",
      "epoch [13/100], loss: -0.042132825357839465\n",
      "epoch [14/100], loss: -0.040451843524351716\n",
      "epoch [15/100], loss: -0.04330385569483042\n",
      "epoch [16/100], loss: -0.040173213463276625\n",
      "epoch [17/100], loss: -0.04450369067490101\n",
      "epoch [18/100], loss: -0.042302350513637066\n",
      "epoch [19/100], loss: -0.04740010667592287\n",
      "epoch [20/100], loss: -0.04389408859424293\n",
      "epoch [21/100], loss: -0.04632096993736923\n",
      "epoch [22/100], loss: -0.04596354952082038\n",
      "epoch [23/100], loss: -0.046998591627925634\n",
      "epoch [24/100], loss: -0.05004139104858041\n",
      "epoch [25/100], loss: -0.04853037279099226\n",
      "epoch [26/100], loss: -0.050496469251811504\n",
      "epoch [27/100], loss: -0.0483465576544404\n",
      "epoch [28/100], loss: -0.04965492291375995\n",
      "epoch [29/100], loss: -0.05036086309701204\n",
      "epoch [30/100], loss: -0.051815410144627094\n",
      "epoch [31/100], loss: -0.05039026262238622\n",
      "epoch [32/100], loss: -0.05044041760265827\n",
      "epoch [33/100], loss: -0.05051620164886117\n",
      "epoch [34/100], loss: -0.0527900627348572\n",
      "epoch [35/100], loss: -0.049915151204913855\n",
      "epoch [36/100], loss: -0.05280156573280692\n",
      "epoch [37/100], loss: -0.05297512374818325\n",
      "epoch [38/100], loss: -0.0551078743301332\n",
      "epoch [39/100], loss: -0.054413634818047285\n",
      "epoch [40/100], loss: -0.055192684987559915\n",
      "epoch [41/100], loss: -0.05545420339331031\n",
      "epoch [42/100], loss: -0.057329175528138876\n",
      "epoch [43/100], loss: -0.056023995857685804\n",
      "epoch [44/100], loss: -0.05662845354527235\n",
      "epoch [45/100], loss: -0.05879673548042774\n",
      "epoch [46/100], loss: -0.05450286436825991\n",
      "epoch [47/100], loss: -0.05685373558662832\n",
      "epoch [48/100], loss: -0.05557198263704777\n",
      "epoch [49/100], loss: -0.05592352943494916\n",
      "epoch [50/100], loss: -0.057128905318677425\n",
      "epoch [51/100], loss: -0.060326939914375544\n",
      "epoch [52/100], loss: -0.05920187383890152\n",
      "epoch [53/100], loss: -0.0570998047478497\n",
      "epoch [54/100], loss: -0.05846288101747632\n",
      "epoch [55/100], loss: -0.056587814120575786\n",
      "epoch [56/100], loss: -0.053983635269105434\n",
      "epoch [57/100], loss: -0.05466069187968969\n",
      "epoch [58/100], loss: -0.04915622065891512\n",
      "epoch [59/100], loss: -0.043726865435019135\n",
      "epoch [60/100], loss: -0.05208008794579655\n",
      "epoch [61/100], loss: -0.036883605644106865\n",
      "epoch [62/100], loss: -0.045304104685783386\n",
      "epoch [63/100], loss: -0.053797115571796894\n",
      "epoch [64/100], loss: -0.054918766021728516\n",
      "epoch [65/100], loss: -0.05409996188245714\n",
      "epoch [66/100], loss: -0.05298970080912113\n",
      "epoch [67/100], loss: -0.0595099376514554\n",
      "epoch [68/100], loss: -0.0598858124576509\n",
      "epoch [69/100], loss: -0.06020234851166606\n",
      "epoch [70/100], loss: -0.054219592828303576\n",
      "epoch [71/100], loss: -0.0438679703802336\n",
      "epoch [72/100], loss: -0.0484497242141515\n",
      "epoch [73/100], loss: -0.05553065752610564\n",
      "epoch [74/100], loss: -0.04669451620429754\n",
      "epoch [75/100], loss: -0.05751929199323058\n",
      "epoch [76/100], loss: -0.0528180378023535\n",
      "epoch [77/100], loss: -0.06040907511487603\n",
      "epoch [78/100], loss: -0.05727416928857565\n",
      "epoch [79/100], loss: -0.06396587123163044\n",
      "epoch [80/100], loss: -0.05768585158511996\n",
      "epoch [81/100], loss: -0.05688484269194305\n",
      "epoch [82/100], loss: -0.05306965438649058\n",
      "epoch [83/100], loss: -0.059638870414346457\n",
      "epoch [84/100], loss: -0.05211125290952623\n",
      "epoch [85/100], loss: -0.06533789215609431\n",
      "epoch [86/100], loss: -0.06583888456225395\n",
      "epoch [87/100], loss: -0.06639264523983002\n",
      "epoch [88/100], loss: -0.059795813634991646\n",
      "epoch [89/100], loss: -0.06006342847831547\n",
      "epoch [90/100], loss: -0.05552362487651408\n",
      "epoch [91/100], loss: -0.06031370582059026\n",
      "epoch [92/100], loss: -0.05327215418219566\n",
      "epoch [93/100], loss: -0.06124949315562844\n",
      "epoch [94/100], loss: -0.06672637211158872\n",
      "epoch [95/100], loss: -0.06963913002982736\n",
      "epoch [96/100], loss: -0.07144793448969722\n",
      "epoch [97/100], loss: -0.07284254115074873\n",
      "epoch [98/100], loss: -0.07156992051750422\n",
      "epoch [99/100], loss: -0.07253924245014787\n",
      "epoch [100/100], loss: -0.07428575213998556\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 2013\n",
      "len des dates 2013\n",
      "epoch [1/100], loss: -0.028928832383826375\n",
      "epoch [2/100], loss: -0.02673913529724814\n",
      "epoch [3/100], loss: -0.028374528395943344\n",
      "epoch [4/100], loss: -0.03659935761243105\n",
      "epoch [5/100], loss: -0.04057436948642135\n",
      "epoch [6/100], loss: -0.04562468943186104\n",
      "epoch [7/100], loss: -0.046838685404509306\n",
      "epoch [8/100], loss: -0.04944829805754125\n",
      "epoch [9/100], loss: -0.050458776066079736\n",
      "epoch [10/100], loss: -0.0517351389862597\n",
      "epoch [11/100], loss: -0.05223360052332282\n",
      "epoch [12/100], loss: -0.05368170980364084\n",
      "epoch [13/100], loss: -0.05399728915654123\n",
      "epoch [14/100], loss: -0.055711600463837385\n",
      "epoch [15/100], loss: -0.051538045052438974\n",
      "epoch [16/100], loss: -0.05365308513864875\n",
      "epoch [17/100], loss: -0.05254164943471551\n",
      "epoch [18/100], loss: -0.05125482939183712\n",
      "epoch [19/100], loss: -0.05149460397660732\n",
      "epoch [20/100], loss: -0.05492162797600031\n",
      "epoch [21/100], loss: -0.0536267408169806\n",
      "epoch [22/100], loss: -0.05681224446743727\n",
      "epoch [23/100], loss: -0.05944846477359533\n",
      "epoch [24/100], loss: -0.05886769387871027\n",
      "epoch [25/100], loss: -0.057274958584457636\n",
      "epoch [26/100], loss: -0.05985919991508126\n",
      "epoch [27/100], loss: -0.058342582546174526\n",
      "epoch [28/100], loss: -0.06234236294403672\n",
      "epoch [29/100], loss: -0.06048586731776595\n",
      "epoch [30/100], loss: -0.05922144744545221\n",
      "epoch [31/100], loss: -0.062027990352362394\n",
      "epoch [32/100], loss: -0.06429705675691366\n",
      "epoch [33/100], loss: -0.06616216385737062\n",
      "epoch [34/100], loss: -0.06619915273040533\n",
      "epoch [35/100], loss: -0.06293633813038468\n",
      "epoch [36/100], loss: -0.06323763355612755\n",
      "epoch [37/100], loss: -0.0611522919498384\n",
      "epoch [38/100], loss: -0.06347266212105751\n",
      "epoch [39/100], loss: -0.06518086465075612\n",
      "epoch [40/100], loss: -0.06352380523458123\n",
      "epoch [41/100], loss: -0.06417932314798236\n",
      "epoch [42/100], loss: -0.06503046164289117\n",
      "epoch [43/100], loss: -0.06613183580338955\n",
      "epoch [44/100], loss: -0.06213882938027382\n",
      "epoch [45/100], loss: -0.05925941048189998\n",
      "epoch [46/100], loss: -0.06409360654652119\n",
      "epoch [47/100], loss: -0.06705739395692945\n",
      "epoch [48/100], loss: -0.06835647858679295\n",
      "epoch [49/100], loss: -0.0683640455827117\n",
      "epoch [50/100], loss: -0.06627308996394277\n",
      "epoch [51/100], loss: -0.06369628058746457\n",
      "epoch [52/100], loss: -0.06248003849759698\n",
      "epoch [53/100], loss: -0.0667719803750515\n",
      "epoch [54/100], loss: -0.07063794042915106\n",
      "epoch [55/100], loss: -0.07205874100327492\n",
      "epoch [56/100], loss: -0.07273894315585494\n",
      "epoch [57/100], loss: -0.07287123799324036\n",
      "epoch [58/100], loss: -0.07136010192334652\n",
      "epoch [59/100], loss: -0.07212642533704638\n",
      "epoch [60/100], loss: -0.06534208403900266\n",
      "epoch [61/100], loss: -0.06995315849781036\n",
      "epoch [62/100], loss: -0.06876423861831427\n",
      "epoch [63/100], loss: -0.07025872590020299\n",
      "epoch [64/100], loss: -0.07409812277182937\n",
      "epoch [65/100], loss: -0.07608798937872052\n",
      "epoch [66/100], loss: -0.07576835993677378\n",
      "epoch [67/100], loss: -0.07789402874186635\n",
      "epoch [68/100], loss: -0.07409007707610726\n",
      "epoch [69/100], loss: -0.07663221005350351\n",
      "epoch [70/100], loss: -0.07512554572895169\n",
      "epoch [71/100], loss: -0.07782541867345572\n",
      "epoch [72/100], loss: -0.07593370229005814\n",
      "epoch [73/100], loss: -0.0691219768486917\n",
      "epoch [74/100], loss: -0.0771313845179975\n",
      "epoch [75/100], loss: -0.07755039259791374\n",
      "epoch [76/100], loss: -0.06968312943354249\n",
      "epoch [77/100], loss: -0.07456723228096962\n",
      "epoch [78/100], loss: -0.07576542859897017\n",
      "epoch [79/100], loss: -0.0780663751065731\n",
      "epoch [80/100], loss: -0.07502463273704052\n",
      "epoch [81/100], loss: -0.07836544187739491\n",
      "epoch [82/100], loss: -0.07361081149429083\n",
      "epoch [83/100], loss: -0.07375531690195203\n",
      "epoch [84/100], loss: -0.07758736005052924\n",
      "epoch [85/100], loss: -0.08297649957239628\n",
      "epoch [86/100], loss: -0.08515054173767567\n",
      "epoch [87/100], loss: -0.085281141102314\n",
      "epoch [88/100], loss: -0.08755544759333134\n",
      "epoch [89/100], loss: -0.08512983471155167\n",
      "epoch [90/100], loss: -0.0807441072538495\n",
      "epoch [91/100], loss: -0.08352654054760933\n",
      "epoch [92/100], loss: -0.08305696910247207\n",
      "epoch [93/100], loss: -0.08312834426760674\n",
      "epoch [94/100], loss: -0.08152946783229709\n",
      "epoch [95/100], loss: -0.07918608980253339\n",
      "epoch [96/100], loss: -0.07388633489608765\n",
      "epoch [97/100], loss: -0.08547346480190754\n",
      "epoch [98/100], loss: -0.08335801539942622\n",
      "epoch [99/100], loss: -0.08323463378474116\n",
      "epoch [100/100], loss: -0.08603028580546379\n",
      "torch.Size([503, 1]) 503\n",
      "len des rdt 2516\n",
      "len des dates 2516\n",
      "epoch [1/100], loss: -0.021843802416697145\n",
      "epoch [2/100], loss: -0.03414111549500376\n",
      "epoch [3/100], loss: -0.04320373432710767\n",
      "epoch [4/100], loss: -0.04165882372763008\n",
      "epoch [5/100], loss: -0.045516568003222346\n",
      "epoch [6/100], loss: -0.044706415850669146\n",
      "epoch [7/100], loss: -0.04898942983709276\n",
      "epoch [8/100], loss: -0.05195071594789624\n",
      "epoch [9/100], loss: -0.05711721535772085\n",
      "epoch [10/100], loss: -0.05723895411938429\n",
      "epoch [11/100], loss: -0.05803028168156743\n",
      "epoch [12/100], loss: -0.05914959544315934\n",
      "epoch [13/100], loss: -0.05989181902259588\n",
      "epoch [14/100], loss: -0.06117378734052181\n",
      "epoch [15/100], loss: -0.061371037270873785\n",
      "epoch [16/100], loss: -0.0618599820882082\n",
      "epoch [17/100], loss: -0.060874965973198414\n",
      "epoch [18/100], loss: -0.06324732257053256\n",
      "epoch [19/100], loss: -0.06440424174070358\n",
      "epoch [20/100], loss: -0.06552740605548024\n",
      "epoch [21/100], loss: -0.06605491926893592\n",
      "epoch [22/100], loss: -0.06732971640303731\n",
      "epoch [23/100], loss: -0.06647328240796924\n",
      "epoch [24/100], loss: -0.06840179022401571\n",
      "epoch [25/100], loss: -0.06570851476863027\n",
      "epoch [26/100], loss: -0.06410814030095935\n",
      "epoch [27/100], loss: -0.06424776697531343\n",
      "epoch [28/100], loss: -0.06502067251130939\n",
      "epoch [29/100], loss: -0.06706068804487586\n",
      "epoch [30/100], loss: -0.06884910305961967\n",
      "epoch [31/100], loss: -0.06790938368067145\n",
      "epoch [32/100], loss: -0.07036592438817024\n",
      "epoch [33/100], loss: -0.07168064126744866\n",
      "epoch [34/100], loss: -0.07286406122148037\n",
      "epoch [35/100], loss: -0.07322037778794765\n",
      "epoch [36/100], loss: -0.07479129312559962\n",
      "epoch [37/100], loss: -0.07449352089315653\n",
      "epoch [38/100], loss: -0.07313137408345938\n",
      "epoch [39/100], loss: -0.07401098357513547\n",
      "epoch [40/100], loss: -0.07602398889139295\n",
      "epoch [41/100], loss: -0.07290335418656468\n",
      "epoch [42/100], loss: -0.07155233947560191\n",
      "epoch [43/100], loss: -0.07448539976030588\n",
      "epoch [44/100], loss: -0.07382500823587179\n",
      "epoch [45/100], loss: -0.07379474211484194\n",
      "epoch [46/100], loss: -0.07420549960806966\n",
      "epoch [47/100], loss: -0.07476902287453413\n",
      "epoch [48/100], loss: -0.07482734462246299\n",
      "epoch [49/100], loss: -0.07686787191778421\n",
      "epoch [50/100], loss: -0.07559676561504602\n",
      "epoch [51/100], loss: -0.07492566108703613\n",
      "epoch [52/100], loss: -0.07857543136924505\n",
      "epoch [53/100], loss: -0.07791190734133124\n",
      "epoch [54/100], loss: -0.07695193216204643\n",
      "epoch [55/100], loss: -0.07853156886994839\n",
      "epoch [56/100], loss: -0.07788986945524812\n",
      "epoch [57/100], loss: -0.0806576912291348\n",
      "epoch [58/100], loss: -0.08025640901178122\n",
      "epoch [59/100], loss: -0.07817809283733368\n",
      "epoch [60/100], loss: -0.07628066325560212\n",
      "epoch [61/100], loss: -0.07692499412223697\n",
      "epoch [62/100], loss: -0.07310276851058006\n",
      "epoch [63/100], loss: -0.07645289180800319\n",
      "epoch [64/100], loss: -0.0808140691369772\n",
      "epoch [65/100], loss: -0.08142974833026528\n",
      "epoch [66/100], loss: -0.08137095719575882\n",
      "epoch [67/100], loss: -0.08173481049016118\n",
      "epoch [68/100], loss: -0.0814692098647356\n",
      "epoch [69/100], loss: -0.07984850741922855\n",
      "epoch [70/100], loss: -0.08206564607098699\n",
      "epoch [71/100], loss: -0.08299256255850196\n",
      "epoch [72/100], loss: -0.08269261242821813\n",
      "epoch [73/100], loss: -0.08344538323581219\n",
      "epoch [74/100], loss: -0.08158408477902412\n",
      "epoch [75/100], loss: -0.08195290435105562\n",
      "epoch [76/100], loss: -0.08059959998354316\n",
      "epoch [77/100], loss: -0.07944977004081011\n",
      "epoch [78/100], loss: -0.08378102630376816\n",
      "epoch [79/100], loss: -0.08491099067032337\n",
      "epoch [80/100], loss: -0.08283148379996419\n",
      "epoch [81/100], loss: -0.08251400152221322\n",
      "epoch [82/100], loss: -0.08335688477382064\n",
      "epoch [83/100], loss: -0.08270152658224106\n",
      "epoch [84/100], loss: -0.07930444879457355\n",
      "epoch [85/100], loss: -0.08267194963991642\n",
      "epoch [86/100], loss: -0.08444203296676278\n",
      "epoch [87/100], loss: -0.08406447526067495\n",
      "epoch [88/100], loss: -0.08351463684812188\n",
      "epoch [89/100], loss: -0.08388155605643988\n",
      "epoch [90/100], loss: -0.08485061628744006\n",
      "epoch [91/100], loss: -0.08463743608444929\n",
      "epoch [92/100], loss: -0.08539023855701089\n",
      "epoch [93/100], loss: -0.08472498040646315\n",
      "epoch [94/100], loss: -0.08718210412189364\n",
      "epoch [95/100], loss: -0.08556377794593573\n",
      "epoch [96/100], loss: -0.08861128892749548\n",
      "epoch [97/100], loss: -0.08626614836975932\n",
      "epoch [98/100], loss: -0.08394182752817869\n",
      "epoch [99/100], loss: -0.08531662076711655\n",
      "epoch [100/100], loss: -0.08560212189331651\n",
      "torch.Size([179, 1]) 179\n",
      "len des rdt 2695\n",
      "len des dates 2695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdt_all = first_rdt\n",
    "alloc_all = first_alloc\n",
    "\n",
    "#entrainement sur 5 cycles Cycle 1 :\n",
    "#Période d’entraînement : 2006 à 2010.\n",
    "#Période d’investissement : 2010 à 2012.\n",
    "#Cycle 2 :\n",
    "#La date de fin d’entraînement est avancée jusqu'en 2012 (couvrant 2006-2012).\n",
    "#La nouvelle période d’investissement couvre alors 2012 à 2014.\n",
    "#etc jusqu'au cycle 5 \n",
    "#rdt_all/alloc_all contient les rendements/alloc sur toute la période \n",
    "\n",
    "#change tp 4\n",
    "for i in range(5):\n",
    "\n",
    "    model = training(x_batches = x_batches[idx_start_invest:idx_end_invest, :, :],\n",
    "                      y_batches= y_batches[idx_start_invest:idx_end_invest, :, :],\n",
    "                      model=model,\n",
    "                      batch_size=64)\n",
    "    \n",
    "    date_end_invest = date_end_invest + datetime.timedelta(days=365*2)\n",
    "    end_date_1st_training = end_date_1st_training + datetime.timedelta(days=365*2)\n",
    "    idx_start_invest, idx_end_invest = get_idx_dates(end_date_1st_training, date_end_invest)\n",
    "\n",
    "    x_investing = x_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "    y_investing = y_batches[idx_start_invest:idx_end_invest, :, :]\n",
    "    y_real = y[idx_start_invest:idx_end_invest, :, :]\n",
    "\n",
    "    #calcul des volatilités\n",
    "    volatilities = calculate_volatility(x_batches=x_investing)\n",
    "\n",
    "    first_rdt, first_alloc = investing_scaled(x_batches= x_investing, y=y_real, volatilities=volatilities, model=model)\n",
    "\n",
    "    print(first_rdt.shape, len(dates_per_feature[idx_start_invest:idx_end_invest]))\n",
    "\n",
    "\n",
    "    rdt_all = torch.cat([rdt_all, first_rdt], dim=0)\n",
    "    print('len des rdt', rdt_all.shape[0])\n",
    "    alloc_all = torch.cat([alloc_all, first_alloc], dim=0)\n",
    "    idx_invest.append((idx_start_invest, idx_end_invest))\n",
    "    print('len des dates', len(dates_per_feature[idx_invest[0][0]:idx_invest[-1][1]]))\n",
    "    dates_invest.append((end_date_1st_training, date_end_invest))\n",
    "\n",
    "\n",
    "alloc_all = alloc_all.numpy()\n",
    "alloc_all = alloc_all.reshape(alloc_all.shape[0], alloc_all.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahah\\AppData\\Local\\Temp\\ipykernel_10784\\2977585624.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_na['Date'] = pd.to_datetime(data_na['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Return</th>\n",
       "      <th>Alloc_AGG</th>\n",
       "      <th>Alloc_DBC</th>\n",
       "      <th>Alloc_VTI</th>\n",
       "      <th>Alloc_^VIX</th>\n",
       "      <th>AGG_y</th>\n",
       "      <th>DBC_y</th>\n",
       "      <th>VTI_y</th>\n",
       "      <th>^VIX_y</th>\n",
       "      <th>Final_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19</td>\n",
       "      <td>0.094613</td>\n",
       "      <td>19.772177</td>\n",
       "      <td>0.211438</td>\n",
       "      <td>7.343978</td>\n",
       "      <td>0.095791</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>-0.092849</td>\n",
       "      <td>0.094613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>0.053121</td>\n",
       "      <td>32.027927</td>\n",
       "      <td>0.144910</td>\n",
       "      <td>4.324626</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.054659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>-0.075321</td>\n",
       "      <td>41.022823</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>1.463578</td>\n",
       "      <td>0.064303</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.074128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-22</td>\n",
       "      <td>0.070810</td>\n",
       "      <td>4.960678</td>\n",
       "      <td>1.045565</td>\n",
       "      <td>10.788657</td>\n",
       "      <td>0.189071</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.075445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-23</td>\n",
       "      <td>-0.045754</td>\n",
       "      <td>2.896227</td>\n",
       "      <td>0.188570</td>\n",
       "      <td>13.922251</td>\n",
       "      <td>0.099532</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.004904</td>\n",
       "      <td>-0.003521</td>\n",
       "      <td>0.051143</td>\n",
       "      <td>-0.045139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>-0.034075</td>\n",
       "      <td>53.899368</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>1.639510</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>-0.037969</td>\n",
       "      <td>-0.033858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>0.057148</td>\n",
       "      <td>62.520584</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.074403</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>-0.076362</td>\n",
       "      <td>0.058167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>51.077675</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>2.692183</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.025720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>49.894943</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>2.758587</td>\n",
       "      <td>0.062451</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.063594</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0.038321</td>\n",
       "      <td>60.388950</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>1.420707</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>0.039510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2695 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Return  Alloc_AGG  Alloc_DBC  Alloc_VTI  Alloc_^VIX  \\\n",
       "0    2010-04-19  0.094613  19.772177   0.211438   7.343978    0.095791   \n",
       "1    2010-04-20  0.053121  32.027927   0.144910   4.324626    0.058925   \n",
       "2    2010-04-21 -0.075321  41.022823   0.213873   1.463578    0.064303   \n",
       "3    2010-04-22  0.070810   4.960678   1.045565  10.788657    0.189071   \n",
       "4    2010-04-23 -0.045754   2.896227   0.188570  13.922251    0.099532   \n",
       "...         ...       ...        ...        ...        ...         ...   \n",
       "2690 2020-12-22 -0.034075  53.899368   0.003227   1.639510    0.003607   \n",
       "2691 2020-12-23  0.057148  62.520584   0.000121   0.074403    0.004039   \n",
       "2692 2020-12-24  0.024314  51.077675   0.001347   2.692183    0.004066   \n",
       "2693 2020-12-28  0.000823  49.894943   0.015985   2.758587    0.062451   \n",
       "2694 2020-12-29  0.038321  60.388950   0.010601   1.420707    0.014840   \n",
       "\n",
       "         AGG_y     DBC_y     VTI_y    ^VIX_y  Final_Return  \n",
       "0     0.001631  0.007936  0.009474 -0.092849      0.094613  \n",
       "1     0.001724  0.004973 -0.000809  0.037508      0.054659  \n",
       "2    -0.002008  0.002474  0.004858  0.009191     -0.074128  \n",
       "3    -0.001246  0.006582  0.006769  0.009108      0.075445  \n",
       "4    -0.000096 -0.004904 -0.003521  0.051143     -0.045139  \n",
       "...        ...       ...       ...       ...           ...  \n",
       "2690 -0.000678  0.012517  0.001710 -0.037969     -0.033858  \n",
       "2691  0.000933  0.002747  0.001673 -0.076362      0.058167  \n",
       "2692  0.000170 -0.006164  0.006327  0.007896      0.025720  \n",
       "2693  0.000169  0.002757 -0.004174  0.063594      0.000955  \n",
       "2694  0.000593  0.006186  0.002691 -0.013432      0.039510  \n",
       "\n",
       "[2695 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe_result = pd.DataFrame({\n",
    "    'Date': pd.Series(dates_per_feature[idx_invest[0][0]:idx_invest[-1][1]]),\n",
    "    'Return': pd.Series(rdt_all.numpy().flatten()),\n",
    "    'Alloc_AGG': pd.Series(alloc_all[:, 0]),\n",
    "    'Alloc_DBC': pd.Series(alloc_all[:, 1]),\n",
    "    'Alloc_VTI': pd.Series(alloc_all[:, 2]),\n",
    "    'Alloc_^VIX': pd.Series(alloc_all[:, 3])\n",
    "})\n",
    "\n",
    "dataframe_result['Date'] = pd.to_datetime(dataframe_result['Date'])\n",
    "data_na['Date'] = pd.to_datetime(data_na['Date'])\n",
    "dataframe_result = pd.merge(dataframe_result, data_na[['Date', 'AGG_y', 'DBC_y', 'VTI_y', '^VIX_y']], on='Date', how='left')\n",
    "\n",
    "dataframe_result['Final_Return'] = (\n",
    "    dataframe_result['Alloc_AGG'] * dataframe_result['AGG_y'] +\n",
    "    dataframe_result['Alloc_DBC'] * dataframe_result['DBC_y'] +\n",
    "    dataframe_result['Alloc_VTI'] * dataframe_result['VTI_y'] +\n",
    "    dataframe_result['Alloc_^VIX'] * dataframe_result['^VIX_y']\n",
    ")\n",
    "\n",
    "dataframe_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annualized mean return: 5.1104\n",
      "annualized std: 1.2098\n",
      "annualized dd: 0.9341\n",
      "Sharpe Ratio: 4.2241\n",
      "Sortino Ratio: 5.4711\n"
     ]
    }
   ],
   "source": [
    "trading_days_per_year = 252\n",
    "\n",
    "mean_daily_return = dataframe_result['Final_Return'].mean()\n",
    "annualized_return = (1+mean_daily_return) ** trading_days_per_year -1\n",
    "\n",
    "std_daily_return = dataframe_result['Final_Return'].std()\n",
    "std_dd_return = dataframe_result[dataframe_result['Final_Return'] < 0]['Final_Return'].std()\n",
    "\n",
    "annualized_volatility = std_daily_return * np.sqrt(trading_days_per_year)\n",
    "annualized_volatility_dd = std_dd_return * np.sqrt(trading_days_per_year)\n",
    "\n",
    "sharpe_ratio = annualized_return / annualized_volatility\n",
    "sortino_ratio = annualized_return / annualized_volatility_dd\n",
    "\n",
    "print(f\"annualized mean return: {annualized_return:.4f}\")\n",
    "print(f\"annualized std: {annualized_volatility:.4f}\")\n",
    "print(f\"annualized dd: {annualized_volatility_dd:.4f}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "print(f\"Sortino Ratio: {sortino_ratio:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riemann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
